{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "121a2d97",
   "metadata": {},
   "source": [
    "First we fetch the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "894ad145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "programmers_train_data = pd.read_csv('C:\\\\fibberio\\\\sandbox\\\\programmers-train.csv', skipinitialspace=True)\n",
    "# programmers_test_data = pd.read_csv('C:\\\\fibberio\\\\sandbox\\\\programmers-test.csv', skipinitialspace=True\n",
    "programmers_test_data = pd.read_csv('C:\\\\fibberio\\\\sandbox\\\\programmers-test.csv', skipinitialspace=True)\n",
    "programmers_train_data = programmers_train_data.drop(['first_name', 'last_name'], axis=1)\n",
    "programmers_test_data = programmers_test_data.drop(['first_name', 'last_name'], axis=1)\n",
    "# delete first column\n",
    "del programmers_train_data[programmers_train_data.columns[0]]\n",
    "del programmers_test_data[programmers_test_data.columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fcdd86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>style</th>\n",
       "      <th>YOE</th>\n",
       "      <th>IDE</th>\n",
       "      <th>Programming language</th>\n",
       "      <th>location</th>\n",
       "      <th>Number of github repos contributed to</th>\n",
       "      <th>Employer</th>\n",
       "      <th>OS</th>\n",
       "      <th>job title</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>spaces</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Emacs</td>\n",
       "      <td>R</td>\n",
       "      <td>Antarctica</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Snapchat</td>\n",
       "      <td>MacOS</td>\n",
       "      <td>Principal Engineer</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>tabs</td>\n",
       "      <td>9.0</td>\n",
       "      <td>pyCharm</td>\n",
       "      <td>Swift</td>\n",
       "      <td>Antarctica</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>Linux</td>\n",
       "      <td>Distinguished Engineer</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>tabs</td>\n",
       "      <td>7.0</td>\n",
       "      <td>XCode</td>\n",
       "      <td>C#</td>\n",
       "      <td>Antarctica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Uber</td>\n",
       "      <td>MacOS</td>\n",
       "      <td>Senior Engineer</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>spaces</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Visual Studio</td>\n",
       "      <td>R</td>\n",
       "      <td>Antarctica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Linux</td>\n",
       "      <td>Principal Engineer</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>tabs</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Eclipse</td>\n",
       "      <td>Java</td>\n",
       "      <td>Antarctica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Windows</td>\n",
       "      <td>SWE 2</td>\n",
       "      <td>33.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>4.0</td>\n",
       "      <td>tabs</td>\n",
       "      <td>6.0</td>\n",
       "      <td>VSCode</td>\n",
       "      <td>Python</td>\n",
       "      <td>Antarctica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Windows</td>\n",
       "      <td>SWE 1</td>\n",
       "      <td>30.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>1.0</td>\n",
       "      <td>tabs</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Visual Studio</td>\n",
       "      <td>Python</td>\n",
       "      <td>Antarctica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Windows</td>\n",
       "      <td>SWE 1</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>3.0</td>\n",
       "      <td>tabs</td>\n",
       "      <td>7.0</td>\n",
       "      <td>XCode</td>\n",
       "      <td>Java</td>\n",
       "      <td>Antarctica</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Uber</td>\n",
       "      <td>Windows</td>\n",
       "      <td>SWE 2</td>\n",
       "      <td>30.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>7.0</td>\n",
       "      <td>tabs</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Emacs</td>\n",
       "      <td>Javascript</td>\n",
       "      <td>North America</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Windows</td>\n",
       "      <td>SWE 2</td>\n",
       "      <td>30.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>8.0</td>\n",
       "      <td>spaces</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Visual Studio</td>\n",
       "      <td>C</td>\n",
       "      <td>Asia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Windows</td>\n",
       "      <td>Senior Engineer</td>\n",
       "      <td>30.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     score   style   YOE            IDE Programming language       location  \\\n",
       "0      8.0  spaces  16.0          Emacs                    R     Antarctica   \n",
       "1      3.0    tabs   9.0        pyCharm                Swift     Antarctica   \n",
       "2      1.0    tabs   7.0          XCode                   C#     Antarctica   \n",
       "3      6.0  spaces  15.0  Visual Studio                    R     Antarctica   \n",
       "4      5.0    tabs   7.0        Eclipse                 Java     Antarctica   \n",
       "..     ...     ...   ...            ...                  ...            ...   \n",
       "795    4.0    tabs   6.0         VSCode               Python     Antarctica   \n",
       "796    1.0    tabs   6.0  Visual Studio               Python     Antarctica   \n",
       "797    3.0    tabs   7.0          XCode                 Java     Antarctica   \n",
       "798    7.0    tabs   8.0          Emacs           Javascript  North America   \n",
       "799    8.0  spaces  20.0  Visual Studio                    C           Asia   \n",
       "\n",
       "     Number of github repos contributed to   Employer       OS  \\\n",
       "0                                      2.0   Snapchat    MacOS   \n",
       "1                                      2.0  Instagram    Linux   \n",
       "2                                      0.0       Uber    MacOS   \n",
       "3                                      0.0     Amazon    Linux   \n",
       "4                                      0.0    Twitter  Windows   \n",
       "..                                     ...        ...      ...   \n",
       "795                                    0.0     Amazon  Windows   \n",
       "796                                    0.0      Apple  Windows   \n",
       "797                                    3.0       Uber  Windows   \n",
       "798                                    1.0  Microsoft  Windows   \n",
       "799                                    0.0    Twitter  Windows   \n",
       "\n",
       "                  job title   age  \n",
       "0        Principal Engineer  32.0  \n",
       "1    Distinguished Engineer  35.0  \n",
       "2           Senior Engineer  32.0  \n",
       "3        Principal Engineer  32.0  \n",
       "4                     SWE 2  33.1  \n",
       "..                      ...   ...  \n",
       "795                   SWE 1  30.7  \n",
       "796                   SWE 1  31.0  \n",
       "797                   SWE 2  30.3  \n",
       "798                   SWE 2  30.2  \n",
       "799         Senior Engineer  30.3  \n",
       "\n",
       "[800 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "programmers_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad2ac153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target_column_name = \"score\"\n",
    "\n",
    "data_train = programmers_train_data\n",
    "data_test = programmers_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec3192b",
   "metadata": {},
   "source": [
    "Now create an MLClient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d30a0f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\RAI-vNext-Preview\\config.json\n"
     ]
    }
   ],
   "source": [
    "from azure.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "ml_client = MLClient.from_config(credential=DefaultAzureCredential(exclude_shared_token_cache_credential=True),\n",
    "                     logging_enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22d9ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.to_parquet(\"programmers-train.parquet\")\n",
    "data_test.to_parquet(\"programmers-test.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b06c44",
   "metadata": {},
   "source": [
    "Upload the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02a309cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading programmers-train.parquet\u001b[32m (< 1 MB): 100%|#######################| 19.5k/19.5k [00:00<00:00, 264kB/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({'paths': [<azure.ml._restclient.v2021_10_01.models._models_py3.UriReference object at 0x00000183C6C305E0>], 'is_anonymous': False, 'auto_increment_version': False, 'name': 'Programmers_Train_from_Notebook', 'description': None, 'tags': {}, 'properties': {}, 'id': '/subscriptions/fac34303-435d-4486-8c3f-7094d82a0b60/resourceGroups/RAIPM/providers/Microsoft.MachineLearningServices/workspaces/RAIPM2/datasets/Programmers_Train_from_Notebook/versions/5', 'base_path': './', 'creation_context': <azure.ml._restclient.v2021_10_01.models._models_py3.SystemData object at 0x00000183C6C30EB0>, 'serialize': <msrest.serialization.Serializer object at 0x00000183C6BF1D90>, 'version': '5', 'local_path': None})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ml.entities import Dataset\n",
    "\n",
    "train_dataset = Dataset(\n",
    "    name=\"Programmers_Train_from_Notebook\",\n",
    "    local_path='programmers-train.parquet',\n",
    ")\n",
    "ml_client.datasets.create_or_update(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30747ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading programmers-test.parquet\u001b[32m (< 1 MB): 100%|########################| 13.3k/13.3k [00:00<00:00, 323kB/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({'paths': [<azure.ml._restclient.v2021_10_01.models._models_py3.UriReference object at 0x00000183C6C30DC0>], 'is_anonymous': False, 'auto_increment_version': False, 'name': 'Programmers_Test_from_Notebook', 'description': None, 'tags': {}, 'properties': {}, 'id': '/subscriptions/fac34303-435d-4486-8c3f-7094d82a0b60/resourceGroups/RAIPM/providers/Microsoft.MachineLearningServices/workspaces/RAIPM2/datasets/Programmers_Test_from_Notebook/versions/5', 'base_path': './', 'creation_context': <azure.ml._restclient.v2021_10_01.models._models_py3.SystemData object at 0x00000183C6C30940>, 'serialize': <msrest.serialization.Serializer object at 0x00000183C6C30490>, 'version': '5', 'local_path': None})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = Dataset(\n",
    "    name=\"Programmers_Test_from_Notebook\",\n",
    "    local_path='programmers-test.parquet',\n",
    ")\n",
    "ml_client.datasets.create_or_update(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22f72fb",
   "metadata": {},
   "source": [
    "# Creating the Model\n",
    "\n",
    "To simplify the model creation process, we're going to use a pipeline.\n",
    "\n",
    "Before we do anything else, we need to specify the version of the RAI components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e0a123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "version_string = '10'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce55f3e6",
   "metadata": {},
   "source": [
    "Now we can create the training script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd44c33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting training_script_reg.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile training_script_reg.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--training_data\", type=str, help=\"Path to training data\")\n",
    "    parser.add_argument(\"--target_column_name\", type=str, help=\"Name of target column\")\n",
    "    parser.add_argument(\"--model_output\", type=str, help=\"Path of output model\")\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "def create_regression_pipeline(X, y):\n",
    "    pipe_cfg = {\n",
    "        'num_cols': X.dtypes[X.dtypes == 'int64'].index.values.tolist(),\n",
    "        'cat_cols': X.dtypes[X.dtypes == 'object'].index.values.tolist(),\n",
    "    }\n",
    "    num_pipe = Pipeline([\n",
    "        ('num_imputer', SimpleImputer(strategy='median')),\n",
    "        ('num_scaler', StandardScaler())\n",
    "    ])\n",
    "    cat_pipe = Pipeline([\n",
    "        ('cat_imputer', SimpleImputer(strategy='constant', fill_value='?')),\n",
    "        ('cat_encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "    ])\n",
    "    feat_pipe = ColumnTransformer([\n",
    "        ('num_pipe', num_pipe, pipe_cfg['num_cols']),\n",
    "        ('cat_pipe', cat_pipe, pipe_cfg['cat_cols'])\n",
    "    ])\n",
    "\n",
    "    # Append classifier to preprocessing pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    pipeline = Pipeline(steps=[('preprocessor', feat_pipe),\n",
    "                               ('model', LinearRegression())])\n",
    "    return pipeline.fit(X, y)\n",
    "\n",
    "def main(args):\n",
    "    current_experiment = Run.get_context().experiment\n",
    "    tracking_uri = current_experiment.workspace.get_mlflow_tracking_uri()\n",
    "    print(\"tracking_uri: {0}\".format(tracking_uri))\n",
    "    mlflow.set_tracking_uri(tracking_uri)\n",
    "    mlflow.set_experiment(current_experiment.name)\n",
    "    \n",
    "    #train_file = None\n",
    "    #for filename in os.listdir(args.training_data):\n",
    "    #    if filename.endswith('.csv'):\n",
    "    #        train_file = filename\n",
    "    #        break\n",
    "    #print(train_file)\n",
    "    #print(os.path.join(args.training_data, train_file))\n",
    "    # Read in data\n",
    "    print(\"Reading data\")\n",
    "    all_data = pd.read_parquet(args.training_data)\n",
    "\n",
    "    print(\"Extracting X_train, y_train\")\n",
    "    print(\"all_data cols: {0}\".format(all_data.columns))\n",
    "    y_train = all_data[args.target_column_name]\n",
    "    X_train = all_data.drop(labels=args.target_column_name, axis=\"columns\")\n",
    "    print(\"X_train cols: {0}\".format(X_train.columns))\n",
    "\n",
    "    print(\"Training model\")\n",
    "    # The estimator can be changed to suit\n",
    "    model = create_regression_pipeline(X_train, y_train)\n",
    "\n",
    "    # Saving model with mlflow - leave this section unchanged\n",
    "    with tempfile.TemporaryDirectory() as td:\n",
    "        print(\"Saving model with MLFlow to temporary directory\")\n",
    "        tmp_output_dir = os.path.join(td, \"my_model_dir\")\n",
    "        mlflow.sklearn.save_model(sk_model=model, path=tmp_output_dir)\n",
    "\n",
    "        print(\"Copying MLFlow model to output path\")\n",
    "        for file_name in os.listdir(tmp_output_dir):\n",
    "            print(\"  Copying: \", file_name)\n",
    "            # As of Python 3.8, copytree will acquire dirs_exist_ok as\n",
    "            # an option, removing the need for listdir\n",
    "            shutil.copy2(src=os.path.join(tmp_output_dir, file_name), dst=os.path.join(args.model_output, file_name))\n",
    "\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)\n",
    "\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6704878b",
   "metadata": {},
   "source": [
    "Now, we want to place this into a component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "209c2424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommandComponent({'auto_increment_version': False, 'is_anonymous': False, 'name': 'ProgrammersTestRegTrainingComponent', 'description': None, 'tags': {}, 'properties': {}, 'id': '/subscriptions/fac34303-435d-4486-8c3f-7094d82a0b60/resourceGroups/RAIPM/providers/Microsoft.MachineLearningServices/workspaces/RAIPM2/components/ProgrammersTestRegTrainingComponent/versions/5', 'base_path': None, 'creation_context': <azure.ml._restclient.v2021_10_01.models._models_py3.SystemData object at 0x00000183C6C92CA0>, 'serialize': <msrest.serialization.Serializer object at 0x00000183C6C87250>, 'command': 'python training_script_reg.py --training_data ${{inputs.training_data}} --target_column_name ${{inputs.target_column_name}} --model_output ${{outputs.model_output}}', 'code': '/subscriptions/fac34303-435d-4486-8c3f-7094d82a0b60/resourceGroups/RAIPM/providers/Microsoft.MachineLearningServices/workspaces/RAIPM2/codes/f456aba5-fbec-43da-b0cb-5f4404c1945d/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/fac34303-435d-4486-8c3f-7094d82a0b60/resourceGroups/RAIPM/providers/Microsoft.MachineLearningServices/workspaces/RAIPM2/environments/AML-RAI-Environment/versions/1', 'distribution': None, 'resources': OrderedDict([('instance_count', 1)]), 'version': '5', 'schema': 'https://azuremlschemas.azureedge.net/stable/commandComponent.schema.json', 'type': 'command', 'display_name': 'Simple reg training component', 'is_deterministic': True, 'inputs': {'training_data': {'name': 'training_data', 'optional': 'False', 'type': 'path'}, 'target_column_name': {'name': 'target_column_name', 'optional': 'False', 'type': 'string'}}, 'outputs': {'model_output': {'name': 'model_output', 'type': 'path'}}, 'yaml_str': None, 'other_parameter': {}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ml.entities import Code, CommandComponent\n",
    "\n",
    "training_code = Code(\n",
    "    local_path='training_script_reg.py'\n",
    ")\n",
    "\n",
    "training_inputs = {\n",
    "    'training_data': { 'type': 'path'},\n",
    "    'target_column_name': { 'type': 'string'}\n",
    "}\n",
    "\n",
    "training_outputs = {\n",
    "    'model_output': { 'type': 'path'}\n",
    "}\n",
    "\n",
    "training_component = CommandComponent(\n",
    "    name=\"ProgrammersTestRegTrainingComponent\",\n",
    "    version=\"5\",\n",
    "    display_name=\"Simple reg training component\",\n",
    "    code=training_code,\n",
    "    environment=f\"AML-RAI-Environment:1\",\n",
    "    inputs=training_inputs,\n",
    "    outputs=training_outputs,\n",
    "    command=\"python training_script_reg.py \" \\\n",
    "            \"--training_data ${{inputs.training_data}} \" \\\n",
    "            \"--target_column_name ${{inputs.target_column_name}} \" \\\n",
    "            \"--model_output ${{outputs.model_output}}\"\n",
    ")\n",
    "\n",
    "ml_client.components.create_or_update(training_component)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83cf52f",
   "metadata": {},
   "source": [
    "# Running a training pipeline\n",
    "Now we have a script which can train a model, we need to run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf80c834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from azure.ml.entities import JobInput, ComponentJob, PipelineJob\n",
    "\n",
    "model_name_suffix = int(time.time())\n",
    "model_name = 'my_trained_reg_nb_model'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e6ff94",
   "metadata": {},
   "source": [
    "This is going to be a two component pipeline. The first will be the one we created above, which will train our model. The second will register it in AzureML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8f93027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The overall inputs for the pipeline\n",
    "\n",
    "pipeline_inputs = {\n",
    "    'target_column_name': target_column_name,\n",
    "    'my_training_data': JobInput(dataset=f\"Programmers_Train_from_Notebook:5\", mode=\"download\"),\n",
    "    'my_test_data': JobInput(dataset=f\"Programmers_Test_from_Notebook:5\", mode=\"download\")\n",
    "}\n",
    "\n",
    "# Specify the training job\n",
    "train_job_inputs = {\n",
    "    'target_column_name': '${{inputs.target_column_name}}',\n",
    "    'training_data': '${{inputs.my_training_data}}',\n",
    "}\n",
    "train_job_outputs = {\n",
    "    'model_output': None\n",
    "}\n",
    "train_job = ComponentJob(\n",
    "    component=f\"ProgrammersTestRegTrainingComponent:5\",\n",
    "    inputs=train_job_inputs,\n",
    "    outputs=train_job_outputs\n",
    ")\n",
    "\n",
    "# The model registration job\n",
    "register_job_inputs = {\n",
    "    'model_input_path': '${{jobs.train-model-job.outputs.model_output}}',\n",
    "    'model_base_name': model_name,\n",
    "    'model_name_suffix': model_name_suffix\n",
    "}\n",
    "register_job_outputs = {\n",
    "    'model_info_output_path': None\n",
    "}\n",
    "register_job = ComponentJob(\n",
    "    component=f\"RegisterModel:{version_string}\",\n",
    "    inputs=register_job_inputs,\n",
    "    outputs=register_job_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc9970f",
   "metadata": {},
   "source": [
    "With our jobs specified, assemble them into a pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e2410db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_registration_pipeline_job = PipelineJob(\n",
    "    experiment_name=f\"Register_Reg_Model_From_Notebook_01\",\n",
    "    description=\"Create and register a model from a notebook\",\n",
    "    jobs={\n",
    "        'train-model-job': train_job,\n",
    "        'register-model-job': register_job,\n",
    "    },\n",
    "    inputs=pipeline_inputs,\n",
    "    outputs=register_job_outputs,\n",
    "    compute=\"rai-cluster\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2a6422",
   "metadata": {},
   "source": [
    "And submit it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d450922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml.entities import PipelineJob\n",
    "\n",
    "def submit_and_wait(ml_client, pipeline_job) -> PipelineJob:\n",
    "    created_job = ml_client.jobs.create_or_update(pipeline_job)\n",
    "    assert created_job is not None\n",
    "\n",
    "    while created_job.status not in ['Completed', 'Failed', 'Canceled', 'NotResponding']:\n",
    "        time.sleep(30)\n",
    "        created_job = ml_client.jobs.get(created_job.name)\n",
    "        print(\"Latest status : {0}\".format(created_job.status))\n",
    "    assert created_job.status == 'Completed'\n",
    "    return created_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42543ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compute is not a known attribute of class <class 'azure.ml._restclient.v2021_10_01.models._models_py3.PipelineJob'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest status : Running\n",
      "Latest status : Completed\n"
     ]
    }
   ],
   "source": [
    "# This is the actual submission\n",
    "\n",
    "training_job = submit_and_wait(ml_client, model_registration_pipeline_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3779f9e4",
   "metadata": {},
   "source": [
    "# Creating the RAI Insights\n",
    "We have a registered model, and can now run a pipeline to create the RAI insights. First off, compute the name of the model we registered (this is not straightforward since the Register Model component is used in testing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4b893bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_model_id = f'{model_name}_{model_name_suffix}:1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce8c009",
   "metadata": {},
   "source": [
    "Now, we create the RAI pipeline itself. There are three 'component stages' in this pipeline:\n",
    "\n",
    "1. Fetch the model\n",
    "1. Construct an empty RAI dashboard\n",
    "1. Run the RAI tool components\n",
    "\n",
    "The job to fetch the registered model is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "670d58b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This won't be necessary once models are types within the pipeline graph\n",
    "\n",
    "fetch_job_inputs = {\n",
    "    'model_id': expected_model_id\n",
    "}\n",
    "fetch_job_outputs = {\n",
    "    'model_info_output_path': None\n",
    "}\n",
    "fetch_job = ComponentJob(\n",
    "    component=f\"FetchRegisteredModel:{version_string}\",\n",
    "    inputs=fetch_job_inputs,\n",
    "    outputs=fetch_job_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941b192f",
   "metadata": {},
   "source": [
    "With this registered model (and our datasets), we can create an empty RAI dashboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1440506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level RAI Insights component\n",
    "\n",
    "# We will reuse the same pipeline_inputs object in the end\n",
    "create_rai_inputs = {\n",
    "    'title': 'Run built from a Notebook',\n",
    "    'task_type': 'regression',\n",
    "    'model_info_path': '${{jobs.fetch-model-job.outputs.model_info_output_path}}',\n",
    "    'train_dataset': '${{inputs.my_training_data}}',\n",
    "    'test_dataset': '${{inputs.my_test_data}}',\n",
    "    'target_column_name': '${{inputs.target_column_name}}',\n",
    "    'categorical_column_names': '[\"location\", \"style\", \"job title\", \"OS\", \"Employer\", \"IDE\", \"Programming language\"]',\n",
    "}\n",
    "create_rai_outputs = {\n",
    "    'rai_insights_dashboard': None # Could theoretically redirect the datastore here\n",
    "}\n",
    "create_rai_job = ComponentJob(\n",
    "    component=f\"RAIInsightsConstructor:{version_string}\",\n",
    "    inputs=create_rai_inputs,\n",
    "    outputs=create_rai_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff017fa",
   "metadata": {},
   "source": [
    "Now, create an instance of each of our RAI tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e254f7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the explanation\n",
    "explain_inputs = {\n",
    "   'comment': 'Insert text here',\n",
    "    'rai_insights_dashboard': '${{jobs.create-rai-job.outputs.rai_insights_dashboard}}'\n",
    "}\n",
    "explain_outputs = {\n",
    "    'explanation': None\n",
    "}\n",
    "explain_job = ComponentJob(\n",
    "    component=f\"RAIInsightsExplanation:{version_string}\",\n",
    "    inputs=explain_inputs,\n",
    "    outputs=explain_outputs\n",
    ")\n",
    "\n",
    "# Setup causal\n",
    "causal_inputs = {\n",
    "    'rai_insights_dashboard': '${{jobs.create-rai-job.outputs.rai_insights_dashboard}}',\n",
    "    'treatment_features': '[\"Number of github repos contributed to\", \"YOE\"]'\n",
    "}\n",
    "causal_outputs = {\n",
    "    'causal': None\n",
    "}\n",
    "causal_job = ComponentJob(\n",
    "    component=f\"RAIInsightsCausal:{version_string}\",\n",
    "    inputs=causal_inputs,\n",
    "    outputs=causal_outputs\n",
    ")\n",
    "\n",
    "# Setup counterfactual\n",
    "counterfactual_inputs = {\n",
    "    'rai_insights_dashboard': '${{jobs.create-rai-job.outputs.rai_insights_dashboard}}',\n",
    "    'total_CFs': '10',\n",
    "    'desired_range': '[5, 10]'\n",
    "}\n",
    "counterfactual_outputs = {\n",
    "    'counterfactual': None\n",
    "}\n",
    "counterfactual_job = ComponentJob(\n",
    "    component=f\"RAIInsightsCounterfactual:{version_string}\",\n",
    "    inputs=counterfactual_inputs,\n",
    "    outputs=counterfactual_outputs\n",
    ")\n",
    "\n",
    "# Setup error analysis\n",
    "error_analysis_inputs = {\n",
    "    'rai_insights_dashboard': '${{jobs.create-rai-job.outputs.rai_insights_dashboard}}',\n",
    "    'filter_features': '[\"style\", \"Employer\"]'\n",
    "}\n",
    "error_analysis_outputs = {\n",
    "    'error_analysis': None\n",
    "}\n",
    "error_analysis_job = ComponentJob(\n",
    "    component=f\"RAIInsightsErrorAnalysis:{version_string}\",\n",
    "    inputs=error_analysis_inputs,\n",
    "    outputs=error_analysis_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d98393",
   "metadata": {},
   "source": [
    "Now the 'gather' component which assembles everything into an `RAIInsights` object, and computes the JSON for the UX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8c71bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the gather component\n",
    "gather_inputs = {\n",
    "    'constructor': '${{jobs.create-rai-job.outputs.rai_insights_dashboard}}',\n",
    "    'insight_1': '${{jobs.explain-job.outputs.explanation}}',\n",
    "    'insight_2': '${{jobs.causal-job.outputs.causal}}',\n",
    "    'insight_3': '${{jobs.counterfactual-job.outputs.counterfactual}}',\n",
    "    'insight_4': '${{jobs.error-analysis-job.outputs.error_analysis}}'\n",
    "}\n",
    "gather_outputs = {\n",
    "    'dashboard': None,\n",
    "    'ux_json': None\n",
    "}\n",
    "gather_job = ComponentJob(\n",
    "    component=f\"RAIInsightsGather:{version_string}\",\n",
    "    inputs=gather_inputs,\n",
    "    outputs=gather_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db19bf2",
   "metadata": {},
   "source": [
    "Finally, the pipeline itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4639a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline to construct the RAI Insights\n",
    "insights_pipeline_job = PipelineJob(\n",
    "    experiment_name=f\"Compute_Insights_from_Notebook_{version_string}\",\n",
    "    description=\"Python submitted Orange insights using fetched model\",\n",
    "    jobs={\n",
    "        'fetch-model-job': fetch_job,\n",
    "        'create-rai-job': create_rai_job,\n",
    "        'causal-job': causal_job,\n",
    "        'counterfactual-job': counterfactual_job,\n",
    "        'error-analysis-job': error_analysis_job,\n",
    "        'explain-job': explain_job,\n",
    "        'gather-job': gather_job\n",
    "    },\n",
    "    inputs=pipeline_inputs,\n",
    "    outputs=None,\n",
    "    compute=\"rai-cluster\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fff73b",
   "metadata": {},
   "source": [
    "And submit it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24a4915c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compute is not a known attribute of class <class 'azure.ml._restclient.v2021_10_01.models._models_py3.PipelineJob'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Completed\n"
     ]
    }
   ],
   "source": [
    "insights_job = submit_and_wait(ml_client, insights_pipeline_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b63f92",
   "metadata": {},
   "source": [
    "# Download and display the insights\n",
    "Now we can download the insights we have computed. To start, we need to obtain the Run id of the 'gather-job' which ran as part of the previous pipeline. We have a helper for this, but the name of the experiment is required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b36de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure_ml_rai import list_rai_insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27324a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_list = list_rai_insights(ml_client, insights_pipeline_job.experiment_name)\n",
    "\n",
    "print(insights_pipeline_job.experiment_name)\n",
    "display(run_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3add2092",
   "metadata": {},
   "source": [
    "We can use the mini SDK to download to a local directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfe847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure_ml_rai import download_rai_insights\n",
    "\n",
    "download_dir = 'my_downloaded_insight'\n",
    "\n",
    "download_rai_insights(\n",
    "    ml_client,\n",
    "    rai_insight_id=run_list[0],\n",
    "    path=download_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4abe2d0",
   "metadata": {},
   "source": [
    "And with everything downloaded, we can load the RAIInsights object and instantiate the dashboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0459d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from responsibleai import RAIInsights\n",
    "from raiwidgets import ResponsibleAIDashboard\n",
    "\n",
    "rai_i = RAIInsights.load(download_dir)\n",
    "\n",
    "ResponsibleAIDashboard(rai_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43d3ffe",
   "metadata": {},
   "source": [
    "If for some reason we only need the JSON file holding the contents of `RAIInsights.get_data()`, we can download the other output port of the 'Gather' component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd0e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure_ml_rai import download_rai_insights_ux\n",
    "\n",
    "download_ux_dir = 'my_ux_insight'\n",
    "\n",
    "download_rai_insights_ux(\n",
    "    ml_client,\n",
    "    rai_insight_id=run_list[0],\n",
    "    path=download_ux_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56eba47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
