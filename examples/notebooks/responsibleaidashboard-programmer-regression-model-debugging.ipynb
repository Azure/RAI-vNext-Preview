{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98605bcd",
   "metadata": {},
   "source": [
    "# Analysis of Synthetic Data\n",
    "\n",
    "This notebook demonstrates a hypothetical scenario of how likely a programmer should be given access to a GPT2 model for inferencing, based on information such as their favorite programming language, preference for tabs vs spaces, OS, location and so forth. Each programmer will be given a score between [0,10] where a score between [7,10] indicates access given to the programmer and [0,7) indicates access denied. The data were synthetically generated via the [PyPI package, Fibber.io](https://pypi.org/project/fibber/).\n",
    "\n",
    "First, we need to specify the version of the RAI components which are available in the workspace. This was specified when the components were uploaded, and will have defaulted to '1':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53b4eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "version_string = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06008690",
   "metadata": {},
   "source": [
    "We also need to give the name of the compute cluster we want to use in AzureML. Later in this notebook, we will create it if it does not already exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1ad79f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_name = \"rai-cluster\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc65dc7",
   "metadata": {},
   "source": [
    "Finally, we need to specify a version for the data and components we will create while running this notebook. This should be unique for the workspace, but the specific value doesn't matter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78053935",
   "metadata": {},
   "outputs": [],
   "source": [
    "rai_programmer_example_version_string = '5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be2b63",
   "metadata": {},
   "source": [
    "## Accessing the Data\n",
    "\n",
    "We supply the synthetic data as a pair of parquet files and accompanying `MLTable` file. We can read them in and take a brief look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f875f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d53df4",
   "metadata": {},
   "source": [
    "Now define the paths to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c7bbe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = 'data-programmer-regression/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c4eb082",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = 'data-programmer-regression/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c4ebb4",
   "metadata": {},
   "source": [
    "Load some data for a quick view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1027fa92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>style</th>\n",
       "      <th>YOE</th>\n",
       "      <th>IDE</th>\n",
       "      <th>Programming language</th>\n",
       "      <th>location</th>\n",
       "      <th>Number of github repos contributed to</th>\n",
       "      <th>Employer</th>\n",
       "      <th>OS</th>\n",
       "      <th>job title</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>tabs</td>\n",
       "      <td>6.0</td>\n",
       "      <td>XCode</td>\n",
       "      <td>Java</td>\n",
       "      <td>Europe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>K</td>\n",
       "      <td>Windows</td>\n",
       "      <td>SWE 2</td>\n",
       "      <td>39.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tabs</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Visual Studio</td>\n",
       "      <td>Java</td>\n",
       "      <td>Europe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Windows</td>\n",
       "      <td>SWE 2</td>\n",
       "      <td>36.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>spaces</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Visual Studio</td>\n",
       "      <td>Java</td>\n",
       "      <td>Europe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Windows</td>\n",
       "      <td>SWE 2</td>\n",
       "      <td>37.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>tabs</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Intellij</td>\n",
       "      <td>Python</td>\n",
       "      <td>Europe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Windows</td>\n",
       "      <td>SWE 1</td>\n",
       "      <td>34.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>tabs</td>\n",
       "      <td>8.0</td>\n",
       "      <td>pyCharm</td>\n",
       "      <td>Python</td>\n",
       "      <td>Europe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>G</td>\n",
       "      <td>Windows</td>\n",
       "      <td>SWE 1</td>\n",
       "      <td>37.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>9.0</td>\n",
       "      <td>spaces</td>\n",
       "      <td>15.0</td>\n",
       "      <td>XCode</td>\n",
       "      <td>Java</td>\n",
       "      <td>Europe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>J</td>\n",
       "      <td>Windows</td>\n",
       "      <td>SWE 2</td>\n",
       "      <td>30.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>2.0</td>\n",
       "      <td>spaces</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Visual Studio</td>\n",
       "      <td>PHP</td>\n",
       "      <td>Europe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Linux</td>\n",
       "      <td>Distinguished Engineer</td>\n",
       "      <td>30.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>8.0</td>\n",
       "      <td>spaces</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Visual Studio</td>\n",
       "      <td>C#</td>\n",
       "      <td>Europe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Windows</td>\n",
       "      <td>SWE 2</td>\n",
       "      <td>33.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>2.0</td>\n",
       "      <td>tabs</td>\n",
       "      <td>6.0</td>\n",
       "      <td>VSCode</td>\n",
       "      <td>Swift</td>\n",
       "      <td>North America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>J</td>\n",
       "      <td>Linux</td>\n",
       "      <td>Distinguished Engineer</td>\n",
       "      <td>28.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tabs</td>\n",
       "      <td>7.0</td>\n",
       "      <td>XCode</td>\n",
       "      <td>Java</td>\n",
       "      <td>Asia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C</td>\n",
       "      <td>Windows</td>\n",
       "      <td>SWE 2</td>\n",
       "      <td>36.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      score   style   YOE            IDE Programming language       location  \\\n",
       "0       4.0    tabs   6.0          XCode                 Java         Europe   \n",
       "1       0.0    tabs   5.0  Visual Studio                 Java         Europe   \n",
       "2       9.0  spaces  18.0  Visual Studio                 Java         Europe   \n",
       "3       8.0    tabs   9.0       Intellij               Python         Europe   \n",
       "4       3.0    tabs   8.0        pyCharm               Python         Europe   \n",
       "...     ...     ...   ...            ...                  ...            ...   \n",
       "1995    9.0  spaces  15.0          XCode                 Java         Europe   \n",
       "1996    2.0  spaces  18.0  Visual Studio                  PHP         Europe   \n",
       "1997    8.0  spaces  14.0  Visual Studio                   C#         Europe   \n",
       "1998    2.0    tabs   6.0         VSCode                Swift  North America   \n",
       "1999    0.0    tabs   7.0          XCode                 Java           Asia   \n",
       "\n",
       "      Number of github repos contributed to Employer       OS  \\\n",
       "0                                       0.0        K  Windows   \n",
       "1                                       0.0        F  Windows   \n",
       "2                                       0.0        A  Windows   \n",
       "3                                       0.0        F  Windows   \n",
       "4                                       3.0        G  Windows   \n",
       "...                                     ...      ...      ...   \n",
       "1995                                    0.0        J  Windows   \n",
       "1996                                    0.0        F    Linux   \n",
       "1997                                    0.0        F  Windows   \n",
       "1998                                    0.0        J    Linux   \n",
       "1999                                    0.0        C  Windows   \n",
       "\n",
       "                   job title   age  \n",
       "0                      SWE 2  39.1  \n",
       "1                      SWE 2  36.1  \n",
       "2                      SWE 2  37.1  \n",
       "3                      SWE 1  34.1  \n",
       "4                      SWE 1  37.9  \n",
       "...                      ...   ...  \n",
       "1995                   SWE 2  30.3  \n",
       "1996  Distinguished Engineer  30.1  \n",
       "1997                   SWE 2  33.1  \n",
       "1998  Distinguished Engineer  28.8  \n",
       "1999                   SWE 2  36.1  \n",
       "\n",
       "[2000 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mltable\n",
    "\n",
    "tbl = mltable.load(train_data_path)\n",
    "train_df: pd.DataFrame = tbl.to_pandas_dataframe()\n",
    "\n",
    "display(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1115ac59",
   "metadata": {},
   "source": [
    "The (synthetic) data are about a collection of programmers, with a 'score' column which we wish to predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b42df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column_name = \"score\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e79b04",
   "metadata": {},
   "source": [
    "First, we need to upload the datasets to our workspace. We start by creating an `MLClient` for interactions with AzureML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "395435fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: /home/workspace/work/RAI-vNext-Preview/config.json\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "ml_client = MLClient.from_config(credential=DefaultAzureCredential(exclude_shared_token_cache_credential=True),\n",
    "                     logging_enable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b501735",
   "metadata": {},
   "source": [
    "We can now upload the data to AzureML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62eb02a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading train (0.02 MBs): 100%|██████████| 19510/19510 [00:00<00:00, 39405.02it/s]\n",
      "\u001b[39m\n",
      "\n",
      "\u001b[32mUploading test (0.01 MBs): 100%|██████████| 13302/13302 [00:00<00:00, 37347.49it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data({'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': ['./programmers-test.parquet'], 'type': 'mltable', 'is_anonymous': False, 'auto_increment_version': False, 'name': 'Programmers_Test_MLTable', 'description': 'RAI programmers test data', 'tags': {}, 'properties': {}, 'id': '/subscriptions/fac34303-435d-4486-8c3f-7094d82a0b60/resourceGroups/RAIPM/providers/Microsoft.MachineLearningServices/workspaces/RAIPM2/data/Programmers_Test_MLTable/versions/6', 'Resource__source_path': None, 'base_path': '/home/workspace/work/RAI-vNext-Preview/examples/notebooks', 'creation_context': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.SystemData object at 0x7f89801a76d0>, 'serialize': <msrest.serialization.Serializer object at 0x7f898018ee20>, 'version': '6', 'latest_version': None, 'path': 'azureml://subscriptions/fac34303-435d-4486-8c3f-7094d82a0b60/resourcegroups/RAIPM/workspaces/RAIPM2/datastores/workspaceblobstore/paths/LocalUpload/d41b357e3e7193f0832161f679eba692/test/'})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "input_train_data = \"Programmers_Train_MLTable\"\n",
    "input_test_data = \"Programmers_Test_MLTable\"\n",
    "\n",
    "train_data = Data(\n",
    "    path=train_data_path,\n",
    "    type=AssetTypes.MLTABLE,\n",
    "    description=\"RAI programmers training data\",\n",
    "    name=input_train_data,\n",
    "    version=rai_programmer_example_version_string,\n",
    ")\n",
    "ml_client.data.create_or_update(train_data)\n",
    "\n",
    "test_data = Data(\n",
    "    path=test_data_path,\n",
    "    type=AssetTypes.MLTABLE,\n",
    "    description=\"RAI programmers test data\",\n",
    "    name=input_test_data,\n",
    "    version=rai_programmer_example_version_string,\n",
    ")\n",
    "ml_client.data.create_or_update(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6815ba75",
   "metadata": {},
   "source": [
    "# Creating the Model\n",
    "\n",
    "To simplify the model creation process, we're going to use a pipeline.\n",
    "\n",
    "We create a directory for the training script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e78d869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.mkdir('programmer_component_src')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea86e55d",
   "metadata": {},
   "source": [
    "Next, we write out our training script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a523f144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing programmer_component_src/training_script_reg.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile programmer_component_src/training_script_reg.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import mltable\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--training_data\", type=str, help=\"Path to training data\")\n",
    "    parser.add_argument(\"--target_column_name\", type=str, help=\"Name of target column\")\n",
    "    parser.add_argument(\"--model_output\", type=str, help=\"Path of output model\")\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "def create_regression_pipeline(X, y):\n",
    "    pipe_cfg = {\n",
    "        'num_cols': X.dtypes[X.dtypes == 'int64'].index.values.tolist(),\n",
    "        'cat_cols': X.dtypes[X.dtypes == 'object'].index.values.tolist(),\n",
    "    }\n",
    "    num_pipe = Pipeline([\n",
    "        ('num_imputer', SimpleImputer(strategy='median')),\n",
    "        ('num_scaler', StandardScaler())\n",
    "    ])\n",
    "    cat_pipe = Pipeline([\n",
    "        ('cat_imputer', SimpleImputer(strategy='constant', fill_value='?')),\n",
    "        ('cat_encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "    ])\n",
    "    feat_pipe = ColumnTransformer([\n",
    "        ('num_pipe', num_pipe, pipe_cfg['num_cols']),\n",
    "        ('cat_pipe', cat_pipe, pipe_cfg['cat_cols'])\n",
    "    ])\n",
    "\n",
    "    # Append classifier to preprocessing pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    pipeline = Pipeline(steps=[('preprocessor', feat_pipe),\n",
    "                               ('model', LinearRegression())])\n",
    "    return pipeline.fit(X, y)\n",
    "\n",
    "def main(args):\n",
    "    current_experiment = Run.get_context().experiment\n",
    "    tracking_uri = current_experiment.workspace.get_mlflow_tracking_uri()\n",
    "    print(\"tracking_uri: {0}\".format(tracking_uri))\n",
    "    mlflow.set_tracking_uri(tracking_uri)\n",
    "    mlflow.set_experiment(current_experiment.name)\n",
    "    \n",
    "    # Read in data\n",
    "    print(\"Reading data\")\n",
    "    tbl = mltable.load(args.training_data)\n",
    "    all_data = tbl.to_pandas_dataframe()\n",
    "\n",
    "    print(\"Extracting X_train, y_train\")\n",
    "    print(\"all_data cols: {0}\".format(all_data.columns))\n",
    "    y_train = all_data[args.target_column_name]\n",
    "    X_train = all_data.drop(labels=args.target_column_name, axis=\"columns\")\n",
    "    print(\"X_train cols: {0}\".format(X_train.columns))\n",
    "\n",
    "    print(\"Training model\")\n",
    "    # The estimator can be changed to suit\n",
    "    model = create_regression_pipeline(X_train, y_train)\n",
    "\n",
    "    # Saving model with mlflow - leave this section unchanged\n",
    "    with tempfile.TemporaryDirectory() as td:\n",
    "        print(\"Saving model with MLFlow to temporary directory\")\n",
    "        tmp_output_dir = os.path.join(td, \"my_model_dir\")\n",
    "        mlflow.sklearn.save_model(sk_model=model, path=tmp_output_dir)\n",
    "\n",
    "        print(\"Copying MLFlow model to output path\")\n",
    "        for file_name in os.listdir(tmp_output_dir):\n",
    "            print(\"  Copying: \", file_name)\n",
    "            # As of Python 3.8, copytree will acquire dirs_exist_ok as\n",
    "            # an option, removing the need for listdir\n",
    "            shutil.copy2(src=os.path.join(tmp_output_dir, file_name), dst=os.path.join(args.model_output, file_name))\n",
    "\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)\n",
    "\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e115dd6e",
   "metadata": {},
   "source": [
    "Now, we can build this into an AzureML component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d54e43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading programmer_component_src (0.0 MBs): 100%|██████████| 3601/3601 [00:00<00:00, 36437.01it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommandComponent({'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.COMPONENT', 'is_anonymous': False, 'name': 'rai_programmers_training_component', 'description': None, 'tags': {}, 'properties': {}, 'id': '/subscriptions/fac34303-435d-4486-8c3f-7094d82a0b60/resourceGroups/RAIPM/providers/Microsoft.MachineLearningServices/workspaces/RAIPM2/components/rai_programmers_training_component/versions/6', 'Resource__source_path': None, 'base_path': './', 'creation_context': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.SystemData object at 0x7f89801893a0>, 'serialize': <msrest.serialization.Serializer object at 0x7f896b62ef40>, 'command': 'python training_script_reg.py --training_data ${{inputs.training_data}} --target_column_name ${{inputs.target_column_name}} --model_output ${{outputs.model_output}}', 'code': '/subscriptions/fac34303-435d-4486-8c3f-7094d82a0b60/resourceGroups/RAIPM/providers/Microsoft.MachineLearningServices/workspaces/RAIPM2/codes/cba5141d-76eb-48e9-81f4-1d64225bf742/versions/1', 'environment_variables': None, 'environment': '/subscriptions/fac34303-435d-4486-8c3f-7094d82a0b60/resourceGroups/RAIPM/providers/Microsoft.MachineLearningServices/workspaces/RAIPM2/environments/AML-RAI-Environment/versions/22', 'distribution': None, 'resources': {'instance_count': 1, 'properties': {}}, 'version': '6', 'latest_version': None, 'schema': 'http://azureml/sdk-2-0/CommandComponent.json', 'type': 'command', 'display_name': 'Programmers training component for RAI example', 'is_deterministic': True, 'inputs': {'training_data': {'type': 'path'}, 'target_column_name': {'type': 'string'}}, 'outputs': {'model_output': {'type': 'path'}}, 'yaml_str': None, 'other_parameter': {}, 'func': <function [component] Programmers training component for RAI example at 0x7f896adb99d0>})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml import load_component\n",
    "\n",
    "yaml_contents = f\"\"\"\n",
    "$schema: http://azureml/sdk-2-0/CommandComponent.json\n",
    "name: rai_programmers_training_component\n",
    "display_name: Programmers training component for RAI example\n",
    "version: {rai_programmer_example_version_string}\n",
    "type: command\n",
    "inputs:\n",
    "  training_data:\n",
    "    type: path\n",
    "  target_column_name:\n",
    "    type: string\n",
    "outputs:\n",
    "  model_output:\n",
    "    type: path\n",
    "code: ./programmer_component_src/\n",
    "environment: azureml:AML-RAI-Environment:{version_string}\n",
    "command: >-\n",
    "  python training_script_reg.py\n",
    "  --training_data ${{{{inputs.training_data}}}}\n",
    "  --target_column_name ${{{{inputs.target_column_name}}}}\n",
    "  --model_output ${{{{outputs.model_output}}}}\n",
    "\"\"\"\n",
    "\n",
    "yaml_filename = \"ProgrammersRegTrainingComp.yaml\"\n",
    "\n",
    "with open(yaml_filename, 'w') as f:\n",
    "    f.write(yaml_contents)\n",
    "    \n",
    "train_component_definition = load_component(\n",
    "    path=yaml_filename\n",
    ")\n",
    "\n",
    "ml_client.components.create_or_update(train_component_definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d165e2b",
   "metadata": {},
   "source": [
    "We need a compute target on which to run our jobs. The following checks whether the compute specified above is present; if not, then the compute target is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e40fc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute: rai-cluster\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "all_compute_names = [x.name for x in ml_client.compute.list()]\n",
    "\n",
    "if compute_name in all_compute_names:\n",
    "    print(f\"Found existing compute: {compute_name}\")\n",
    "else:\n",
    "    my_compute = AmlCompute(\n",
    "        name=compute_name,\n",
    "        size=\"Standard_DS2_v2\",\n",
    "        min_instances=0,\n",
    "        max_instances=4,\n",
    "        idle_time_before_scale_down=3600\n",
    "    )\n",
    "    ml_client.compute.begin_create_or_update(my_compute)\n",
    "    print(\"Initiated compute creation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8eb868",
   "metadata": {},
   "source": [
    "## Running a training pipeline\n",
    "\n",
    "Now that we have our training component, we can run it. We begin by generating a unique name for the mode;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad76242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "model_name_suffix = int(time.time())\n",
    "model_name = 'rai_programmer_example_reg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49615a7",
   "metadata": {},
   "source": [
    "Next, we define our training pipeline. This has two components. The first is the training component which we defined above. The second is a component to register the model in AzureML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb6c6cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import dsl, Input\n",
    "\n",
    "register_component = ml_client.components.get(\n",
    "    name=\"register_model\", version=version_string\n",
    ")\n",
    "train_model_component = ml_client.components.get(\n",
    "    name=\"rai_programmers_training_component\", version=rai_programmer_example_version_string\n",
    ")\n",
    "programmers_train_mltable = Input(\n",
    "    type=\"mltable\", path=f\"{input_train_data}:{rai_programmer_example_version_string}\", mode=\"download\"\n",
    ")\n",
    "programmers_test_mltable = Input(\n",
    "    type=\"mltable\", path=f\"{input_test_data}:{rai_programmer_example_version_string}\", mode=\"download\"\n",
    ")\n",
    "\n",
    "@dsl.pipeline(\n",
    "    compute=compute_name,\n",
    "    description=\"Register Model for RAI Programmers example\",\n",
    "    experiment_name=f\"RAI_Programmers_Example_Model_Training_{model_name_suffix}\",\n",
    ")\n",
    "def my_training_pipeline(target_column_name, training_data):\n",
    "    trained_model = train_component_definition(\n",
    "        target_column_name=target_column_name,\n",
    "        training_data=training_data\n",
    "    )\n",
    "    trained_model.set_limits(timeout=120)\n",
    "\n",
    "    _ = register_component(\n",
    "        model_input_path=trained_model.outputs.model_output,\n",
    "        model_base_name=model_name,\n",
    "        model_name_suffix=model_name_suffix,\n",
    "    )\n",
    "\n",
    "    return {}\n",
    "\n",
    "model_registration_pipeline_job = my_training_pipeline(target_column_name, programmers_train_mltable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa66ea6",
   "metadata": {},
   "source": [
    "With the training pipeline defined, we can submit it for execution in AzureML. We define a helper function to wait for the job to complete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f854eef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Completed\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import PipelineJob\n",
    "\n",
    "def submit_and_wait(ml_client, pipeline_job) -> PipelineJob:\n",
    "    created_job = ml_client.jobs.create_or_update(pipeline_job)\n",
    "    assert created_job is not None\n",
    "\n",
    "    while created_job.status not in ['Completed', 'Failed', 'Canceled', 'NotResponding']:\n",
    "        time.sleep(30)\n",
    "        created_job = ml_client.jobs.get(created_job.name)\n",
    "        print(\"Latest status : {0}\".format(created_job.status))\n",
    "    assert created_job.status == 'Completed'\n",
    "    return created_job\n",
    "\n",
    "# This is the actual submission\n",
    "training_job = submit_and_wait(ml_client, model_registration_pipeline_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0722395e",
   "metadata": {},
   "source": [
    "## Creating the RAI Insights\n",
    "\n",
    "Now that we have our model, we can generate RAI insights for it. We will need the `id` of the registered model, which will be as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d3e6e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_model_id = f'{model_name}_{model_name_suffix}:1'\n",
    "azureml_model_id = f'azureml:{expected_model_id}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310aa659",
   "metadata": {},
   "source": [
    "Next, we load the RAI components, so that we can construct a pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d67b942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rai_constructor_component = ml_client.components.get(\n",
    "    name=\"rai_insights_constructor\", version=version_string\n",
    ")\n",
    "\n",
    "rai_explanation_component = ml_client.components.get(\n",
    "    name=\"rai_insights_explanation\", version=version_string\n",
    ")\n",
    "\n",
    "rai_causal_component = ml_client.components.get(\n",
    "    name=\"rai_insights_causal\", version=version_string\n",
    ")\n",
    "\n",
    "rai_counterfactual_component = ml_client.components.get(\n",
    "    name=\"rai_insights_counterfactual\", version=version_string\n",
    ")\n",
    "\n",
    "rai_erroranalysis_component = ml_client.components.get(\n",
    "    name=\"rai_insights_erroranalysis\", version=version_string\n",
    ")\n",
    "\n",
    "rai_gather_component = ml_client.components.get(\n",
    "    name=\"rai_insights_gather\", version=version_string\n",
    ")\n",
    "\n",
    "rai_scorecard_component = ml_client.components.get(\n",
    "    name=\"rai_score_card\", version=version_string\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933b22cd",
   "metadata": {},
   "source": [
    "## Score card generation config\n",
    "For score card generation, we need some additional configuration in a separate json file. Here we configure the following model performance metrics for reporting:\n",
    "- mean absolute error\n",
    "- mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "872e1fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "score_card_config_dict = {\n",
    "  \"Model\": {\n",
    "    \"ModelName\": \"GPT2 Access\",\n",
    "    \"ModelType\": \"Regression\",\n",
    "    \"ModelSummary\": \"This is a regression model to analyzer how likely a programmer is given access to gpt 2\"\n",
    "  },\n",
    "  \"Metrics\": {\n",
    "    \"mean_absolute_error\": {\n",
    "      \"threshold\": \"<=20\"\n",
    "    },\n",
    "    \"mean_squared_error\": {}\n",
    "  },\n",
    "  \"FeatureImportance\": {\n",
    "    \"top_n\": 6\n",
    "  },\n",
    "  \"DataExplorer\": {\n",
    "    \"features\": [\n",
    "      \"YOE\",\n",
    "      \"age\"\n",
    "    ]\n",
    "  },\n",
    "  \"Fairness\": {\n",
    "    \"metric\": [\"mean_squared_error\", \"mean_absolute_error\"],\n",
    "    \"sensitive_features\": [\"IDE\", \"style\"],\n",
    "    \"fairness_evaluation_kind\": \"difference\"\n",
    "  }\n",
    "}\n",
    "\n",
    "score_card_config_filename = \"rai_programmer_regression_score_card_config.json\"\n",
    "\n",
    "with open(score_card_config_filename, 'w') as f:\n",
    "    json.dump(score_card_config_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98cd2d9",
   "metadata": {},
   "source": [
    "We can now specify our pipeline. Complex objects (such as lists of column names) have to be converted to JSON strings before being passed to the components. Note that the timeout for the counterfactual job is noticeably longer, since generating counterfactual points is a comparatively slow process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a62105a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "score_card_config_path = Input(\n",
    "    type=\"uri_file\",\n",
    "    path=score_card_config_filename,\n",
    "    mode=\"download\"\n",
    ")\n",
    "\n",
    "categorical_columns = json.dumps([\"location\", \"style\", \"job title\", \"OS\", \"Employer\", \"IDE\", \"Programming language\"])\n",
    "treatment_features = json.dumps([\"Number of github repos contributed to\", \"YOE\"])\n",
    "desired_range = json.dumps([5, 10])\n",
    "filter_columns = json.dumps([\"style\", \"Employer\"])\n",
    "\n",
    "@dsl.pipeline(\n",
    "        compute=compute_name,\n",
    "        description=\"Example RAI computation on programmers data\",\n",
    "        experiment_name=f\"RAI_Programmers_Example_RAIInsights_Computation_{model_name_suffix}\",\n",
    "    )\n",
    "def rai_programmer_regression_pipeline(\n",
    "        target_column_name,\n",
    "        train_data,\n",
    "        test_data,\n",
    "        score_card_config_path,\n",
    "    ):\n",
    "        # Initiate the RAIInsights\n",
    "        create_rai_job = rai_constructor_component(\n",
    "            title=\"RAI Dashboard Example\",\n",
    "            task_type=\"regression\",\n",
    "            model_info=expected_model_id,\n",
    "            model_input=Input(type=AssetTypes.MLFLOW_MODEL, path=azureml_model_id),\n",
    "            train_dataset=train_data,\n",
    "            test_dataset=test_data,\n",
    "            target_column_name=target_column_name,\n",
    "            categorical_column_names=categorical_columns\n",
    "        )\n",
    "        create_rai_job.set_limits(timeout=120)\n",
    "        \n",
    "        # Add an explanation\n",
    "        explain_job = rai_explanation_component(\n",
    "            comment=\"Explanation for the programmers dataset\",\n",
    "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n",
    "        )\n",
    "        explain_job.set_limits(timeout=120)\n",
    "        \n",
    "        # Add causal analysis\n",
    "        causal_job = rai_causal_component(\n",
    "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n",
    "            treatment_features=treatment_features,\n",
    "        )\n",
    "        causal_job.set_limits(timeout=180)\n",
    "        \n",
    "        # Add counterfactual analysis\n",
    "        counterfactual_job = rai_counterfactual_component(\n",
    "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n",
    "            total_cfs=10,\n",
    "            desired_range=desired_range\n",
    "        )\n",
    "        counterfactual_job.set_limits(timeout=600)\n",
    "        \n",
    "        # Add error analysis\n",
    "        erroranalysis_job = rai_erroranalysis_component(\n",
    "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n",
    "            filter_features=filter_columns\n",
    "        )\n",
    "        erroranalysis_job.set_limits(timeout=120)\n",
    "        \n",
    "        # Combine everything\n",
    "        rai_gather_job = rai_gather_component(\n",
    "            constructor=create_rai_job.outputs.rai_insights_dashboard,\n",
    "            insight_1=explain_job.outputs.explanation,\n",
    "            insight_2=causal_job.outputs.causal,\n",
    "            insight_3=counterfactual_job.outputs.counterfactual,\n",
    "            insight_4=erroranalysis_job.outputs.error_analysis,\n",
    "        )\n",
    "        rai_gather_job.set_limits(timeout=120)\n",
    "\n",
    "        rai_gather_job.outputs.dashboard.mode = \"upload\"\n",
    "        rai_gather_job.outputs.ux_json.mode = \"upload\"\n",
    "\n",
    "        # Generate score card in pdf format for a summary report on model performance,\n",
    "        # and observe distrbution of error between prediction vs ground truth.\n",
    "        rai_scorecard_job = rai_scorecard_component(\n",
    "            dashboard=rai_gather_job.outputs.dashboard,\n",
    "            pdf_generation_config=score_card_config_path\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"dashboard\": rai_gather_job.outputs.dashboard,\n",
    "            \"ux_json\": rai_gather_job.outputs.ux_json,\n",
    "            \"scorecard\": rai_scorecard_job.outputs.scorecard\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5b14a9",
   "metadata": {},
   "source": [
    "Next, we define the pipeline object itself, and ensure that the outputs will be available for download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4d86ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from azure.ai.ml import Output\n",
    "\n",
    "insights_pipeline_job = rai_programmer_regression_pipeline(\n",
    "    target_column_name=target_column_name,\n",
    "    train_data=programmers_train_mltable,\n",
    "    test_data=programmers_test_mltable,\n",
    "    score_card_config_path=score_card_config_path,\n",
    ")\n",
    "\n",
    "rand_path = str(uuid.uuid4())\n",
    "insights_pipeline_job.outputs.dashboard = Output(\n",
    "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/dashboard/\",\n",
    "    mode=\"upload\",\n",
    "    type=\"uri_folder\",\n",
    ")\n",
    "insights_pipeline_job.outputs.ux_json = Output(\n",
    "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/ux_json/\",\n",
    "    mode=\"upload\",\n",
    "    type=\"uri_folder\",\n",
    ")\n",
    "insights_pipeline_job.outputs.scorecard = Output(\n",
    "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/scorecard/\",\n",
    "    mode=\"upload\",\n",
    "    type=\"uri_folder\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f34573",
   "metadata": {},
   "source": [
    "And submit the pipeline to AzureML for execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ca757f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading rai_programmer_regression_score_card_config.json\u001b[32m (< 1 MB): 100%|██████████| 492/492 [00:00<00:00, 4.72kB/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Completed\n"
     ]
    }
   ],
   "source": [
    "insights_job = submit_and_wait(ml_client, insights_pipeline_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1381768a",
   "metadata": {},
   "source": [
    "The dashboard should appear in the AzureML portal in the registered model view. The following cell computes the expected URI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ab611",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_id = ml_client._operation_scope.subscription_id\n",
    "rg_name = ml_client._operation_scope.resource_group_name\n",
    "ws_name = ml_client.workspace_name\n",
    "\n",
    "expected_uri = f\"https://ml.azure.com/model/{expected_model_id}/model_analysis?wsid=/subscriptions/{sub_id}/resourcegroups/{rg_name}/workspaces/{ws_name}\"\n",
    "\n",
    "print(f\"Please visit {expected_uri} to see your analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3513d61c",
   "metadata": {},
   "source": [
    "## Downloading the Scorecard PDF\n",
    "\n",
    "We can download the scorecard PDF from our pipeline as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e1350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_directory = \".\"\n",
    "\n",
    "ml_client.jobs.download(\n",
    "    insights_job.name, download_path=target_directory, output_name=\"scorecard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212c161b",
   "metadata": {},
   "source": [
    "We can also download the dashboard, and view it in this notebook. Note that this is fragile with respect to the Python version and conda environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641f6675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import pathlib\n",
    "from responsibleai import RAIInsights\n",
    "from raiwidgets import ResponsibleAIDashboard\n",
    "with tempfile.TemporaryDirectory() as dashboard_path:\n",
    "        ml_client.jobs.download(\n",
    "            insights_job.name, download_path=dashboard_path, output_name=\"dashboard\"\n",
    "        )\n",
    "        expected_path = pathlib.Path(dashboard_path) / 'named-outputs' / 'dashboard'\n",
    "        # This load is very fragile with respect to Python version and conda environment\n",
    "        rai_i = RAIInsights.load(expected_path)\n",
    "        ResponsibleAIDashboard(rai_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a8dff9",
   "metadata": {},
   "source": [
    "## Constructing the pipeline in YAML\n",
    "\n",
    "It is also possible to specify the pipeline as a YAML file, and submit that using the command line. We will now create a YAML specification of the above pipeline and submit that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624bb0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_contents = f\"\"\"\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json\n",
    "experiment_name: RAI_Programmer_Example_YAML_{rai_programmer_example_version_string}\n",
    "type: pipeline\n",
    "\n",
    "inputs:\n",
    "  target_column_name: {target_column_name}\n",
    "  my_training_data:\n",
    "    type: mltable\n",
    "    path: azureml:{input_train_data}:{rai_programmer_example_version_string}\n",
    "    mode: download\n",
    "  my_test_data:\n",
    "    type: mltable\n",
    "    path: azureml:{input_test_data}:{rai_programmer_example_version_string}\n",
    "    mode: download\n",
    "\n",
    "settings:\n",
    "  default_datastore: azureml:workspaceblobstore\n",
    "  default_compute: azureml:cpucluster\n",
    "  continue_on_step_failure: false\n",
    "\n",
    "jobs:\n",
    "  create_rai_job:\n",
    "    type: command\n",
    "    component: azureml:rai_insights_constructor:{version_string}\n",
    "    inputs:\n",
    "      title: RAI Programmer Analysis from YAML\n",
    "      task_type: regression\n",
    "      model_info: {expected_model_id}\n",
    "      model_input:\n",
    "        type: mlflow_model\n",
    "        path: {azureml_model_id}\n",
    "      train_dataset: ${{{{parent.inputs.my_training_data}}}}\n",
    "      test_dataset: ${{{{parent.inputs.my_test_data}}}}\n",
    "      target_column_name: ${{{{parent.inputs.target_column_name}}}}\n",
    "      categorical_column_names: '[\"location\", \"job title\", \"OS\", \"Employer\", \"IDE\", \"Programming language\", \"style\"]'\n",
    "      \n",
    "  explain_01:\n",
    "    type: command\n",
    "    component: azureml:rai_insights_explanation:{version_string}\n",
    "    inputs:\n",
    "      comment: Explanation from YAML for RAI Programmer example\n",
    "      rai_insights_dashboard: ${{{{parent.jobs.create_rai_job.outputs.rai_insights_dashboard}}}}\n",
    "\n",
    "  causal_01:\n",
    "    type: command\n",
    "    component: azureml:rai_insights_causal:{version_string}\n",
    "    inputs:\n",
    "      rai_insights_dashboard: ${{{{parent.jobs.create_rai_job.outputs.rai_insights_dashboard}}}}\n",
    "      treatment_features: '[\"Number of github repos contributed to\", \"YOE\"]'\n",
    "\n",
    "  counterfactual_01:\n",
    "    type: command\n",
    "    component: azureml:rai_insights_counterfactual:{version_string}\n",
    "    inputs:\n",
    "      rai_insights_dashboard: ${{{{parent.jobs.create_rai_job.outputs.rai_insights_dashboard}}}}\n",
    "      total_CFs: 10\n",
    "      desired_range: '[5, 10]'\n",
    "\n",
    "  error_analysis_01:\n",
    "    type: command\n",
    "    component: azureml:rai_insights_erroranalysis:{version_string}\n",
    "    inputs:\n",
    "      rai_insights_dashboard: ${{{{parent.jobs.create_rai_job.outputs.rai_insights_dashboard}}}}\n",
    "      filter_features: '[\"style\", \"Employer\"]'\n",
    "\n",
    "  gather_01:\n",
    "    type: command\n",
    "    component: azureml:rai_insights_gather:{version_string}\n",
    "    inputs:\n",
    "      constructor: ${{{{parent.jobs.create_rai_job.outputs.rai_insights_dashboard}}}}\n",
    "      insight_1: ${{{{parent.jobs.causal_01.outputs.causal}}}}\n",
    "      insight_2: ${{{{parent.jobs.counterfactual_01.outputs.counterfactual}}}}\n",
    "      insight_3: ${{{{parent.jobs.error_analysis_01.outputs.error_analysis}}}}\n",
    "      insight_4: ${{{{parent.jobs.explain_01.outputs.explanation}}}}\n",
    "\"\"\"\n",
    "\n",
    "yaml_pipeline_filename = \"rai_programmer_example.yaml\"\n",
    "\n",
    "with open(yaml_pipeline_filename, 'w') as f:\n",
    "    f.write(yaml_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5f2dd",
   "metadata": {},
   "source": [
    "The created file can then be submitted using the Azure CLI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf9bb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_line = ['az', 'ml', 'job', 'create',\n",
    "            '--resource-group', rg_name,\n",
    "            '--workspace', ws_name,\n",
    "            '--file', yaml_pipeline_filename]\n",
    "\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    cmd = subprocess.run(cmd_line, check=True, shell=True, capture_output=True)\n",
    "except subprocess.CalledProcessError as cpe:\n",
    "    print(f\"Error invoking: {cpe.args}\")\n",
    "    print(cpe.stdout)\n",
    "    print(cpe.stderr)\n",
    "    raise\n",
    "else:\n",
    "    print(\"Azure CLI submission completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32566b10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8fd340b5477ca1a0b454d48a3973beff39fee032ada47a04f6f3725b469a8988"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
