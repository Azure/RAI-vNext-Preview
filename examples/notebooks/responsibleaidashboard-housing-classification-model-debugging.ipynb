{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "587f4596",
   "metadata": {},
   "source": [
    "# Debug housing price predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6550b0",
   "metadata": {},
   "source": [
    "This notebook demonstrates the use of the `responsibleai` API to assess a classification model trained on Kaggle's apartments dataset (https://www.kaggle.com/alphaepsilon/housing-prices-dataset). The model predicts if the house sells for more than median price or not. It walks through the API calls necessary to create a widget with model analysis insights, then guides a visual analysis of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20f25c3",
   "metadata": {},
   "source": [
    "## Launch Responsible AI Toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a122e129",
   "metadata": {},
   "source": [
    "The following section examines the code necessary to create datasets and a model. It then generates insights using the `responsibleai` API that can be visually analyzed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4736295c",
   "metadata": {},
   "source": [
    "### Train a Model\n",
    "*The following section can be skipped. It loads a dataset and trains a model for illustrative purposes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebae7586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927997ce",
   "metadata": {},
   "source": [
    "First, load the apartment dataset and specify the different types of features. Then, clean it and put it into a dataframe with named columns. After loading and cleaning the data, split the datapoints into training and test sets. Assemble separate datasets for the full sample and the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99f4447e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def split_label(dataset, target_feature):\n",
    "    X = dataset.drop([target_feature], axis=1)\n",
    "    y = dataset[[target_feature]]\n",
    "    return X, y\n",
    "\n",
    "def clean_data(X, y, target_feature):\n",
    "    features = X.columns.values.tolist()\n",
    "    classes = y[target_feature].unique().tolist()\n",
    "    pipe_cfg = {\n",
    "        'num_cols': X.dtypes[X.dtypes == 'int64'].index.values.tolist(),\n",
    "        'cat_cols': X.dtypes[X.dtypes == 'object'].index.values.tolist(),\n",
    "    }\n",
    "    num_pipe = Pipeline([\n",
    "        ('num_imputer', SimpleImputer(strategy='median'))#,\n",
    "        #('num_scaler', StandardScaler())\n",
    "    ])\n",
    "    cat_pipe = Pipeline([\n",
    "        ('cat_imputer', SimpleImputer(strategy='constant', fill_value='?')),\n",
    "        ('cat_encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "    ])\n",
    "    feat_pipe = ColumnTransformer([\n",
    "        ('num_pipe', num_pipe, pipe_cfg['num_cols']),\n",
    "        ('cat_pipe', cat_pipe, pipe_cfg['cat_cols'])\n",
    "    ])\n",
    "    X = feat_pipe.fit_transform(X)\n",
    "    print(pipe_cfg['cat_cols'])\n",
    "    return X, feat_pipe, features, classes\n",
    "\n",
    "target_feature = 'Sold_HigherThan_Median'\n",
    "categorical_features = []\n",
    "\n",
    "outdirname = 'responsibleai.12.28.21'\n",
    "try:\n",
    "    from urllib import urlretrieve\n",
    "except ImportError:\n",
    "    from urllib.request import urlretrieve\n",
    "zipfilename = outdirname + '.zip'\n",
    "urlretrieve('https://publictestdatasets.blob.core.windows.net/data/' + zipfilename, zipfilename)\n",
    "with zipfile.ZipFile(zipfilename, 'r') as unzip:\n",
    "    unzip.extractall('.')\n",
    "\n",
    "all_data = pd.read_csv('apartments-train.csv')\n",
    "all_data = all_data.drop(['SalePrice','SalePriceK'], axis=1)\n",
    "X, y = split_label(all_data, target_feature)\n",
    "\n",
    "\n",
    "X_train_original, X_test_original, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=7, stratify=y)\n",
    "\n",
    "X_train, feat_pipe, features, classes = clean_data(X_train_original, y_train, target_feature)\n",
    "y_train = y_train[target_feature].to_numpy()\n",
    "\n",
    "X_test = feat_pipe.transform(X_test_original)\n",
    "y_test = y_test[target_feature].to_numpy()\n",
    "\n",
    "train_data = X_train_original.copy()\n",
    "train_data[target_feature] = y_train\n",
    "\n",
    "test_data = X_test_original.copy()\n",
    "test_data[target_feature] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424f10b3",
   "metadata": {},
   "source": [
    "# Get the Data to AzureML\n",
    "\n",
    "First, save the data to files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00fa1264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to files\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving to files\")\n",
    "train_data.to_parquet(\"housing_train.parquet\", index=False)\n",
    "test_data.to_parquet(\"housing_test.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebcf911",
   "metadata": {},
   "source": [
    "Create an `MLClient`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26324cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\Users\\riedgar\\source\\repos\\RAI-vNext-Preview\\config.json\n"
     ]
    }
   ],
   "source": [
    "from azure.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "ml_client = MLClient.from_config(credential=DefaultAzureCredential(exclude_shared_token_cache_credential=True),\n",
    "                     logging_enable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11059bef",
   "metadata": {},
   "source": [
    "Upload the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6efef915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({'paths': [<azure.ml._restclient.v2021_10_01.models._models_py3.UriReference object at 0x0000025CA0AABFC8>], 'is_anonymous': False, 'auto_increment_version': False, 'name': 'Housing_Test_from_Notebook', 'description': None, 'tags': {}, 'properties': {}, 'id': '/subscriptions/589c7ae9-223e-45e3-a191-98433e0821a9/resourceGroups/amlisdkv2-rg-1643673716/providers/Microsoft.MachineLearningServices/workspaces/amlisdkv21643673716/datasets/Housing_Test_from_Notebook/versions/2', 'base_path': './', 'creation_context': <azure.ml._restclient.v2021_10_01.models._models_py3.SystemData object at 0x0000025CA0AABC88>, 'serialize': <msrest.serialization.Serializer object at 0x0000025CA0A99CC8>, 'version': '2', 'local_path': None})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ml.entities import Dataset\n",
    "\n",
    "train_dataset = Dataset(\n",
    "    name=\"Housing_Train_from_Notebook\",\n",
    "    local_path=\"housing_train.parquet\",\n",
    ")\n",
    "ml_client.datasets.create_or_update(train_dataset)\n",
    "\n",
    "test_dataset = Dataset(\n",
    "    name=\"Housing_Test_from_Notebook\",\n",
    "    local_path=\"housing_test.parquet\",\n",
    ")\n",
    "ml_client.datasets.create_or_update(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cd5b8c",
   "metadata": {},
   "source": [
    "# Train the Model in AzureML\n",
    "\n",
    "To simplify the model creation process, we're going to use a pipeline.\n",
    "\n",
    "Before we do anything else, we need to specify the version of the RAI components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a4fb1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "version_string = '1643680970'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe77a46a",
   "metadata": {},
   "source": [
    "Now we can create the training script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdae1092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing housing_training_script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile housing_training_script.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--training_data\", type=str, help=\"Path to training data\")\n",
    "    parser.add_argument(\"--target_column_name\", type=str, help=\"Name of target column\")\n",
    "    parser.add_argument(\"--model_output\", type=str, help=\"Path of output model\")\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    current_experiment = Run.get_context().experiment\n",
    "    tracking_uri = current_experiment.workspace.get_mlflow_tracking_uri()\n",
    "    print(\"tracking_uri: {0}\".format(tracking_uri))\n",
    "    mlflow.set_tracking_uri(tracking_uri)\n",
    "    mlflow.set_experiment(current_experiment.name)\n",
    "\n",
    "    # Read in data\n",
    "    print(\"Reading data\")\n",
    "    all_data = pd.read_parquet(args.training_data)\n",
    "\n",
    "    print(\"Extracting X_train, y_train\")\n",
    "    print(\"all_data cols: {0}\".format(all_data.columns))\n",
    "    y_train = all_data[args.target_column_name]\n",
    "    X_train = all_data.drop(labels=args.target_column_name, axis=\"columns\")\n",
    "    print(\"X_train cols: {0}\".format(X_train.columns))\n",
    "\n",
    "    print(\"Training model\")\n",
    "    # The estimator can be changed to suit\n",
    "    model = LGBMClassifier(n_estimators=5)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Saving model with mlflow - leave this section unchanged\n",
    "    with tempfile.TemporaryDirectory() as td:\n",
    "        print(\"Saving model with MLFlow to temporary directory\")\n",
    "        tmp_output_dir = os.path.join(td, \"my_model_dir\")\n",
    "        mlflow.sklearn.save_model(sk_model=model, path=tmp_output_dir)\n",
    "\n",
    "        print(\"Copying MLFlow model to output path\")\n",
    "        for file_name in os.listdir(tmp_output_dir):\n",
    "            print(\"  Copying: \", file_name)\n",
    "            # As of Python 3.8, copytree will acquire dirs_exist_ok as\n",
    "            # an option, removing the need for listdir\n",
    "            shutil.copy2(src=os.path.join(tmp_output_dir, file_name), dst=os.path.join(args.model_output, file_name))\n",
    "\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)\n",
    "\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da408bd4",
   "metadata": {},
   "source": [
    "Place this script into a component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "917bd3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading housing_training_script.py\u001b[32m (< 1 MB): 100%|##############################| 2.46k/2.46k [00:00<00:00, 19.1kB/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommandComponent({'auto_increment_version': False, 'is_anonymous': False, 'name': 'HousingTrainingComponent', 'description': None, 'tags': {}, 'properties': {}, 'id': '/subscriptions/589c7ae9-223e-45e3-a191-98433e0821a9/resourceGroups/amlisdkv2-rg-1643673716/providers/Microsoft.MachineLearningServices/workspaces/amlisdkv21643673716/components/HousingTrainingComponent/versions/3', 'base_path': None, 'creation_context': <azure.ml._restclient.v2021_10_01.models._models_py3.SystemData object at 0x0000025CA0AB7208>, 'serialize': <msrest.serialization.Serializer object at 0x0000025CA0B8CD48>, 'command': 'python housing_training_script.py --training_data ${{inputs.training_data}} --target_column_name ${{inputs.target_column_name}} --model_output ${{outputs.model_output}}', 'code': '/subscriptions/589c7ae9-223e-45e3-a191-98433e0821a9/resourceGroups/amlisdkv2-rg-1643673716/providers/Microsoft.MachineLearningServices/workspaces/amlisdkv21643673716/codes/7f56844e-c13d-41ec-83d8-8b35592dc302/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/589c7ae9-223e-45e3-a191-98433e0821a9/resourceGroups/amlisdkv2-rg-1643673716/providers/Microsoft.MachineLearningServices/workspaces/amlisdkv21643673716/environments/AML-RAI-Environment/versions/1643680970', 'distribution': None, 'resources': OrderedDict([('instance_count', 1)]), 'version': '3', 'schema': 'https://azuremlschemas.azureedge.net/stable/commandComponent.schema.json', 'type': 'command', 'display_name': 'Simple training component for housing Dataset', 'is_deterministic': True, 'inputs': {'training_data': {'name': 'training_data', 'optional': 'False', 'type': 'path'}, 'target_column_name': {'name': 'target_column_name', 'optional': 'False', 'type': 'string'}}, 'outputs': {'model_output': {'name': 'model_output', 'type': 'path'}}, 'yaml_str': None, 'other_parameter': {}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ml.entities import Code, CommandComponent\n",
    "\n",
    "training_code = Code(\n",
    "    local_path='housing_training_script.py'\n",
    ")\n",
    "\n",
    "training_inputs = {\n",
    "    'training_data': { 'type': 'path'},\n",
    "    'target_column_name': { 'type': 'string'}\n",
    "}\n",
    "\n",
    "training_outputs = {\n",
    "    'model_output': { 'type': 'path'}\n",
    "}\n",
    "\n",
    "training_component = CommandComponent(\n",
    "    name=\"HousingTrainingComponent\",\n",
    "    version=\"3\",\n",
    "    display_name=\"Simple training component for housing Dataset\",\n",
    "    code=training_code,\n",
    "    environment=f\"AML-RAI-Environment:{version_string}\",\n",
    "    inputs=training_inputs,\n",
    "    outputs=training_outputs,\n",
    "    command=\"python housing_training_script.py \" \\\n",
    "            \"--training_data ${{inputs.training_data}} \" \\\n",
    "            \"--target_column_name ${{inputs.target_column_name}} \" \\\n",
    "            \"--model_output ${{outputs.model_output}}\"\n",
    ")\n",
    "\n",
    "ml_client.components.create_or_update(training_component)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7638b1a",
   "metadata": {},
   "source": [
    "# Running a training pipeline\n",
    "Now we have a script which can train a model, we need to run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1a53849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from azure.ml.entities import JobInput, ComponentJob, PipelineJob\n",
    "\n",
    "model_name_suffix = int(time.time())\n",
    "model_name = 'my_housing_nb_model'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b9b4e9",
   "metadata": {},
   "source": [
    "This is going to be a two component pipeline. The first will be the one we created above, which will train our model. The second will register it in AzureML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0c14a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The overall inputs for the pipeline\n",
    "\n",
    "pipeline_inputs = {\n",
    "    'target_column_name': target_feature,\n",
    "    'my_training_data': JobInput(dataset=f\"Housing_Train_from_Notebook:1\"),\n",
    "    'my_test_data': JobInput(dataset=f\"Housing_Test_from_Notebook:1\")\n",
    "}\n",
    "\n",
    "# Specify the training job\n",
    "train_job_inputs = {\n",
    "    'target_column_name': '${{inputs.target_column_name}}',\n",
    "    'training_data': '${{inputs.my_training_data}}',\n",
    "}\n",
    "train_job_outputs = {\n",
    "    'model_output': None\n",
    "}\n",
    "train_job = ComponentJob(\n",
    "    component=f\"HousingTrainingComponent:3\",\n",
    "    inputs=train_job_inputs,\n",
    "    outputs=train_job_outputs\n",
    ")\n",
    "\n",
    "# The model registration job\n",
    "register_job_inputs = {\n",
    "    'model_input_path': '${{jobs.train-model-job.outputs.model_output}}',\n",
    "    'model_base_name': model_name,\n",
    "    'model_name_suffix': model_name_suffix\n",
    "}\n",
    "register_job_outputs = {\n",
    "    'model_info_output_path': None\n",
    "}\n",
    "register_job = ComponentJob(\n",
    "    component=f\"RegisterModel:{version_string}\",\n",
    "    inputs=register_job_inputs,\n",
    "    outputs=register_job_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ff0383",
   "metadata": {},
   "source": [
    "With our jobs specified, assemble them into a pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6233e310",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_registration_pipeline_job = PipelineJob(\n",
    "    experiment_name=f\"Register_Housing_Model_From_Notebook_01\",\n",
    "    description=\"Create and register a model from a notebook\",\n",
    "    jobs={\n",
    "        'train-model-job': train_job,\n",
    "        'register-model-job': register_job,\n",
    "    },\n",
    "    inputs=pipeline_inputs,\n",
    "    outputs=register_job_outputs,\n",
    "    compute=\"cpucluster\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376e680f",
   "metadata": {},
   "source": [
    "And submit it to AzureML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d614a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compute is not a known attribute of class <class 'azure.ml._restclient.v2021_10_01.models._models_py3.PipelineJob'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Completed\n"
     ]
    }
   ],
   "source": [
    "from azure.ml.entities import PipelineJob\n",
    "\n",
    "def submit_and_wait(ml_client, pipeline_job) -> PipelineJob:\n",
    "    created_job = ml_client.jobs.create_or_update(pipeline_job)\n",
    "    assert created_job is not None\n",
    "\n",
    "    while created_job.status not in ['Completed', 'Failed', 'Canceled', 'NotResponding']:\n",
    "        time.sleep(30)\n",
    "        created_job = ml_client.jobs.get(created_job.name)\n",
    "        print(\"Latest status : {0}\".format(created_job.status))\n",
    "    assert created_job.status == 'Completed'\n",
    "    return created_job\n",
    "\n",
    "# This is the actual submission\n",
    "training_job = submit_and_wait(ml_client, model_registration_pipeline_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b29ec13",
   "metadata": {},
   "source": [
    "# Creating the RAI Insights\n",
    "We have a registered model, and can now run a pipeline to create the RAI insights. First off, compute the name of the model we registered (this is not straightforward since the Register Model component is used in testing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6debb20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_model_id = f'{model_name}_{model_name_suffix}:1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f9b84",
   "metadata": {},
   "source": [
    "Now, we create the RAI pipeline itself. There are three 'component stages' in this pipeline:\n",
    "\n",
    "1. Fetch the model\n",
    "1. Construct an empty RAI dashboard\n",
    "1. Run the RAI tool components\n",
    "\n",
    "The job to fetch the registered model is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34d8ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This won't be necessary once models are types within the pipeline graph\n",
    "\n",
    "fetch_job_inputs = {\n",
    "    'model_id': expected_model_id\n",
    "}\n",
    "fetch_job_outputs = {\n",
    "    'model_info_output_path': None\n",
    "}\n",
    "fetch_job = ComponentJob(\n",
    "    component=f\"FetchRegisteredModel:{version_string}\",\n",
    "    inputs=fetch_job_inputs,\n",
    "    outputs=fetch_job_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e06ec14",
   "metadata": {},
   "source": [
    "With this registered model (and our datasets), we can create an empty RAI dashboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55c7c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Top level RAI Insights component\n",
    "\n",
    "# We will reuse the same pipeline_inputs object in the end\n",
    "create_rai_inputs = {\n",
    "    'title': 'Run built from a Notebook',\n",
    "    'task_type': 'classification',\n",
    "    'model_info_path': '${{jobs.fetch-model-job.outputs.model_info_output_path}}',\n",
    "    'train_dataset': '${{inputs.my_training_data}}',\n",
    "    'test_dataset': '${{inputs.my_test_data}}',\n",
    "    'target_column_name': '${{inputs.target_column_name}}',\n",
    "    'categorical_column_names': json.dumps(categorical_features),\n",
    "    'classes': '[\"Less than median\", \"More than median\"]'\n",
    "}\n",
    "create_rai_outputs = {\n",
    "    'rai_insights_dashboard': None # Could theoretically redirect the datastore here\n",
    "}\n",
    "create_rai_job = ComponentJob(\n",
    "    component=f\"RAIInsightsConstructor:{version_string}\",\n",
    "    inputs=create_rai_inputs,\n",
    "    outputs=create_rai_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aa443d",
   "metadata": {},
   "source": [
    "Now, create instances of our RAI tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5d3b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the explanation\n",
    "explain_inputs = {\n",
    "   'comment': 'Insert text here',\n",
    "    'rai_insights_dashboard': '${{jobs.create-rai-job.outputs.rai_insights_dashboard}}'\n",
    "}\n",
    "explain_outputs = {\n",
    "    'explanation': None\n",
    "}\n",
    "explain_job = ComponentJob(\n",
    "    component=f\"RAIInsightsExplanation:{version_string}\",\n",
    "    inputs=explain_inputs,\n",
    "    outputs=explain_outputs\n",
    ")\n",
    "\n",
    "\n",
    "# Setup counterfactual\n",
    "counterfactual_inputs = {\n",
    "    'rai_insights_dashboard': '${{jobs.create-rai-job.outputs.rai_insights_dashboard}}',\n",
    "    'total_CFs': '10',\n",
    "    'desired_class': 'opposite'\n",
    "}\n",
    "counterfactual_outputs = {\n",
    "    'counterfactual': None\n",
    "}\n",
    "counterfactual_job = ComponentJob(\n",
    "    component=f\"RAIInsightsCounterfactual:{version_string}\",\n",
    "    inputs=counterfactual_inputs,\n",
    "    outputs=counterfactual_outputs\n",
    ")\n",
    "\n",
    "# Setup error analysis\n",
    "error_analysis_inputs = {\n",
    "    'rai_insights_dashboard': '${{jobs.create-rai-job.outputs.rai_insights_dashboard}}',\n",
    "}\n",
    "error_analysis_outputs = {\n",
    "    'error_analysis': None\n",
    "}\n",
    "error_analysis_job = ComponentJob(\n",
    "    component=f\"RAIInsightsErrorAnalysis:{version_string}\",\n",
    "    inputs=error_analysis_inputs,\n",
    "    outputs=error_analysis_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7878e4",
   "metadata": {},
   "source": [
    "Now the 'gather' component which assembles everything into an `RAIInsights` object, and computes the JSON for the UX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce4c8c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the gather component\n",
    "gather_inputs = {\n",
    "    'constructor': '${{jobs.create-rai-job.outputs.rai_insights_dashboard}}',\n",
    "    'insight_1': '${{jobs.explain-job.outputs.explanation}}',\n",
    "    'insight_2': '${{jobs.counterfactual-job.outputs.counterfactual}}',\n",
    "    'insight_3': '${{jobs.error-analysis-job.outputs.error_analysis}}'\n",
    "}\n",
    "gather_outputs = {\n",
    "    'dashboard': None,\n",
    "    'ux_json': None\n",
    "}\n",
    "gather_job = ComponentJob(\n",
    "    component=f\"RAIInsightsGather:{version_string}\",\n",
    "    inputs=gather_inputs,\n",
    "    outputs=gather_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41297748",
   "metadata": {},
   "source": [
    "Finally, the pipeline itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80b99ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline to construct the RAI Insights\n",
    "insights_pipeline_job = PipelineJob(\n",
    "    experiment_name=f\"Compute_Housing_Insights_from_Notebook_{version_string}\",\n",
    "    description=\"Python submitted Housing insights using fetched model\",\n",
    "    jobs={\n",
    "        'fetch-model-job': fetch_job,\n",
    "        'create-rai-job': create_rai_job,\n",
    "        'counterfactual-job': counterfactual_job,\n",
    "        'error-analysis-job': error_analysis_job,\n",
    "        'explain-job': explain_job,\n",
    "        'housing-gather-job': gather_job\n",
    "    },\n",
    "    inputs=pipeline_inputs,\n",
    "    outputs=None,\n",
    "    compute=\"cpucluster\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a37993a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compute is not a known attribute of class <class 'azure.ml._restclient.v2021_10_01.models._models_py3.PipelineJob'> and will be ignored\n"
     ]
    },
    {
     "ename": "HttpResponseError",
     "evalue": "(UserError) classes is not a valid input name per component definition\nCode: UserError\nMessage: classes is not a valid input name per component definition\nAdditional Information:Type: ComponentName\nInfo: {\n    \"value\": \"managementfrontend\"\n}Type: Correlation\nInfo: {\n    \"value\": {\n        \"operation\": \"37605c3abcd69040a1158efcffc075b4\",\n        \"request\": \"bba768de16e05a46\"\n    }\n}Type: Environment\nInfo: {\n    \"value\": \"uksouth\"\n}Type: Location\nInfo: {\n    \"value\": \"uksouth\"\n}Type: Time\nInfo: {\n    \"value\": \"2022-02-01T19:30:14.0791464+00:00\"\n}Type: DebugInfo\nInfo: {\n    \"value\": {\n        \"type\": \"Microsoft.MachineLearning.Common.Core.ServiceInvocationException\",\n        \"message\": \"Service invocation failed!\\r\\nRequest: POST https://uksouth.api.azureml.ms/studioservice/api/subscriptions/589c7ae9-223e-45e3-a191-98433e0821a9/resourceGroups/amlisdkv2-rg-1643673716/workspaces/amlisdkv21643673716/PipelineRuns/SubmitUnsavedPipelineRunWithGraph\\r\\nStatus Code: 400 BadRequest\\r\\nError Code: UserError\\r\\nReason Phrase: classes is not a valid input name per component definition\\r\\nResponse Body: {\\n  \\\"error\\\": {\\n    \\\"code\\\": \\\"UserError\\\",\\n    \\\"severity\\\": null,\\n    \\\"message\\\": \\\"classes is not a valid input name per component definition\\\",\\n    \\\"messageFormat\\\": null,\\n    \\\"messageParameters\\\": null,\\n    \\\"referenceCode\\\": null,\\n    \\\"detailsUri\\\": null,\\n    \\\"target\\\": null,\\n    \\\"details\\\": [],\\n    \\\"innerError\\\": null,\\n    \\\"debugInfo\\\": null,\\n    \\\"additionalInfo\\\": null\\n  },\\n  \\\"correlation\\\": {\\n    \\\"operation\\\": \\\"37605c3abcd69040a1158efcffc075b4\\\",\\n    \\\"request\\\": \\\"41b6febef9ec16bc\\\"\\n  },\\n  \\\"environment\\\": \\\"uksouth\\\",\\n  \\\"location\\\": \\\"uksouth\\\",\\n  \\\"time\\\": \\\"2022-02-01T19:30:14.0639836+00:00\\\",\\n  \\\"componentName\\\": \\\"Designer-MiddleTier-Service\\\"\\n}\",\n        \"stackTrace\": \"   at Microsoft.MachineLearning.Common.WebApi.Client.ServiceInvoker._MakeRequest(UriBuilder builder, MethodDetails details, CancellationToken cancellationToken, Nullable`1 initialStreamPosition, Uri fallbackServiceAddress, Object[] parameters) in /mnt/vss/_work/1/s/src/azureml-api/src/Common/WebApi.Client/ServiceInvoker.cs:line 821\\n   at Polly.Retry.AsyncRetryEngine.ImplementationAsync[TResult](Func`3 action, Context context, CancellationToken cancellationToken, ExceptionPredicates shouldRetryExceptionPredicates, ResultPredicates`1 shouldRetryResultPredicates, Func`5 onRetryAsync, Int32 permittedRetryCount, IEnumerable`1 sleepDurationsEnumerable, Func`4 sleepDurationProvider, Boolean continueOnCapturedContext)\\n   at Polly.AsyncPolicy.ExecuteAsync[TResult](Func`3 action, Context context, CancellationToken cancellationToken, Boolean continueOnCapturedContext)\\n   at Microsoft.MachineLearning.Common.WebApi.Client.ServiceInvoker._Invoke[T](String methodId, Object[] parameters) in /mnt/vss/_work/1/s/src/azureml-api/src/Common/WebApi.Client/ServiceInvoker.cs:line 196\\n   at Microsoft.MachineLearning.ManagementFrontEnd.Services.PipelineJobService.Create(WorkspaceContext2 workspace, String jobId, PipelineJob jobDefinitionMfe) in /mnt/vss/_work/1/s/src/azureml-api/src/ManagementFrontEnd/Services/Services/PipelineJobService.cs:line 107\\n   at Microsoft.MachineLearning.ManagementFrontEnd.Services.JobService.CreateOrUpdateJob(WorkspaceContext2 workspace, String jobId, Resource`1 jobDefinition, IList`1 supportedJobTypes, String userToken) in /mnt/vss/_work/1/s/src/azureml-api/src/ManagementFrontEnd/Services/Services/JobService.cs:line 147\\n   at Microsoft.MachineLearning.ManagementFrontEnd.EntryPoints.Api.V20211001.Controllers.JobController.CreateOrUpdateJob(WorkspaceContext2 workspaceContext, String id, String apiVersion, Resource`1 definition) in /mnt/vss/_work/1/s/src/azureml-api/src/ManagementFrontEnd/EntryPoints/Api/V20211001/Controllers/JobController.cs:line 96\\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ActionMethodExecutor.TaskOfIActionResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, Object controller, Object[] arguments)\\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeActionMethodAsync>g__Logged|12_1(ControllerActionInvoker invoker)\\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeNextActionFilterAsync>g__Awaited|10_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Rethrow(ActionExecutedContextSealed context)\\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)\\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeInnerFilterAsync>g__Awaited|13_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeNextExceptionFilterAsync>g__Awaited|25_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\",\n        \"innerException\": null,\n        \"data\": {},\n        \"errorResponse\": {\n            \"error\": {\n                \"code\": \"UserError\",\n                \"severity\": null,\n                \"message\": \"classes is not a valid input name per component definition\",\n                \"messageFormat\": null,\n                \"messageParameters\": null,\n                \"referenceCode\": null,\n                \"detailsUri\": null,\n                \"target\": null,\n                \"details\": [],\n                \"innerError\": null,\n                \"debugInfo\": null,\n                \"additionalInfo\": null\n            },\n            \"correlation\": {\n                \"operation\": \"37605c3abcd69040a1158efcffc075b4\",\n                \"request\": \"41b6febef9ec16bc\"\n            },\n            \"environment\": \"uksouth\",\n            \"location\": \"uksouth\",\n            \"time\": \"2022-02-01T19:30:14.0639836+00:00\",\n            \"componentName\": \"Designer-MiddleTier-Service\"\n        }\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-7325edf2ac25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minsights_job\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubmit_and_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mml_client\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minsights_pipeline_job\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-5e709127603b>\u001b[0m in \u001b[0;36msubmit_and_wait\u001b[1;34m(ml_client, pipeline_job)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msubmit_and_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mml_client\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpipeline_job\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mPipelineJob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mcreated_job\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mml_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_or_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline_job\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mcreated_job\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\rai-components-37\\lib\\site-packages\\azure\\ml\\_operations\\job_operations.py\u001b[0m in \u001b[0;36mcreate_or_update\u001b[1;34m(self, job, description, compute, tags, experiment_name, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m                 \u001b[0mworkspace_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workspace_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrest_job_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m                 \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m             )\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_local_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\rai-components-37\\lib\\site-packages\\azure\\ml\\_restclient\\v2021_10_01\\operations\\_jobs_operations.py\u001b[0m in \u001b[0;36mcreate_or_update\u001b[1;34m(self, id, resource_group_name, workspace_name, body, **kwargs)\u001b[0m\n\u001b[0;32m    397\u001b[0m             \u001b[0mmap_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merror_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m             \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mErrorResponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mHttpResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mARMErrorFormat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHttpResponseError\u001b[0m: (UserError) classes is not a valid input name per component definition\nCode: UserError\nMessage: classes is not a valid input name per component definition\nAdditional Information:Type: ComponentName\nInfo: {\n    \"value\": \"managementfrontend\"\n}Type: Correlation\nInfo: {\n    \"value\": {\n        \"operation\": \"37605c3abcd69040a1158efcffc075b4\",\n        \"request\": \"bba768de16e05a46\"\n    }\n}Type: Environment\nInfo: {\n    \"value\": \"uksouth\"\n}Type: Location\nInfo: {\n    \"value\": \"uksouth\"\n}Type: Time\nInfo: {\n    \"value\": \"2022-02-01T19:30:14.0791464+00:00\"\n}Type: DebugInfo\nInfo: {\n    \"value\": {\n        \"type\": \"Microsoft.MachineLearning.Common.Core.ServiceInvocationException\",\n        \"message\": \"Service invocation failed!\\r\\nRequest: POST https://uksouth.api.azureml.ms/studioservice/api/subscriptions/589c7ae9-223e-45e3-a191-98433e0821a9/resourceGroups/amlisdkv2-rg-1643673716/workspaces/amlisdkv21643673716/PipelineRuns/SubmitUnsavedPipelineRunWithGraph\\r\\nStatus Code: 400 BadRequest\\r\\nError Code: UserError\\r\\nReason Phrase: classes is not a valid input name per component definition\\r\\nResponse Body: {\\n  \\\"error\\\": {\\n    \\\"code\\\": \\\"UserError\\\",\\n    \\\"severity\\\": null,\\n    \\\"message\\\": \\\"classes is not a valid input name per component definition\\\",\\n    \\\"messageFormat\\\": null,\\n    \\\"messageParameters\\\": null,\\n    \\\"referenceCode\\\": null,\\n    \\\"detailsUri\\\": null,\\n    \\\"target\\\": null,\\n    \\\"details\\\": [],\\n    \\\"innerError\\\": null,\\n    \\\"debugInfo\\\": null,\\n    \\\"additionalInfo\\\": null\\n  },\\n  \\\"correlation\\\": {\\n    \\\"operation\\\": \\\"37605c3abcd69040a1158efcffc075b4\\\",\\n    \\\"request\\\": \\\"41b6febef9ec16bc\\\"\\n  },\\n  \\\"environment\\\": \\\"uksouth\\\",\\n  \\\"location\\\": \\\"uksouth\\\",\\n  \\\"time\\\": \\\"2022-02-01T19:30:14.0639836+00:00\\\",\\n  \\\"componentName\\\": \\\"Designer-MiddleTier-Service\\\"\\n}\",\n        \"stackTrace\": \"   at Microsoft.MachineLearning.Common.WebApi.Client.ServiceInvoker._MakeRequest(UriBuilder builder, MethodDetails details, CancellationToken cancellationToken, Nullable`1 initialStreamPosition, Uri fallbackServiceAddress, Object[] parameters) in /mnt/vss/_work/1/s/src/azureml-api/src/Common/WebApi.Client/ServiceInvoker.cs:line 821\\n   at Polly.Retry.AsyncRetryEngine.ImplementationAsync[TResult](Func`3 action, Context context, CancellationToken cancellationToken, ExceptionPredicates shouldRetryExceptionPredicates, ResultPredicates`1 shouldRetryResultPredicates, Func`5 onRetryAsync, Int32 permittedRetryCount, IEnumerable`1 sleepDurationsEnumerable, Func`4 sleepDurationProvider, Boolean continueOnCapturedContext)\\n   at Polly.AsyncPolicy.ExecuteAsync[TResult](Func`3 action, Context context, CancellationToken cancellationToken, Boolean continueOnCapturedContext)\\n   at Microsoft.MachineLearning.Common.WebApi.Client.ServiceInvoker._Invoke[T](String methodId, Object[] parameters) in /mnt/vss/_work/1/s/src/azureml-api/src/Common/WebApi.Client/ServiceInvoker.cs:line 196\\n   at Microsoft.MachineLearning.ManagementFrontEnd.Services.PipelineJobService.Create(WorkspaceContext2 workspace, String jobId, PipelineJob jobDefinitionMfe) in /mnt/vss/_work/1/s/src/azureml-api/src/ManagementFrontEnd/Services/Services/PipelineJobService.cs:line 107\\n   at Microsoft.MachineLearning.ManagementFrontEnd.Services.JobService.CreateOrUpdateJob(WorkspaceContext2 workspace, String jobId, Resource`1 jobDefinition, IList`1 supportedJobTypes, String userToken) in /mnt/vss/_work/1/s/src/azureml-api/src/ManagementFrontEnd/Services/Services/JobService.cs:line 147\\n   at Microsoft.MachineLearning.ManagementFrontEnd.EntryPoints.Api.V20211001.Controllers.JobController.CreateOrUpdateJob(WorkspaceContext2 workspaceContext, String id, String apiVersion, Resource`1 definition) in /mnt/vss/_work/1/s/src/azureml-api/src/ManagementFrontEnd/EntryPoints/Api/V20211001/Controllers/JobController.cs:line 96\\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ActionMethodExecutor.TaskOfIActionResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, Object controller, Object[] arguments)\\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeActionMethodAsync>g__Logged|12_1(ControllerActionInvoker invoker)\\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeNextActionFilterAsync>g__Awaited|10_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Rethrow(ActionExecutedContextSealed context)\\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)\\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeInnerFilterAsync>g__Awaited|13_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeNextExceptionFilterAsync>g__Awaited|25_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\",\n        \"innerException\": null,\n        \"data\": {},\n        \"errorResponse\": {\n            \"error\": {\n                \"code\": \"UserError\",\n                \"severity\": null,\n                \"message\": \"classes is not a valid input name per component definition\",\n                \"messageFormat\": null,\n                \"messageParameters\": null,\n                \"referenceCode\": null,\n                \"detailsUri\": null,\n                \"target\": null,\n                \"details\": [],\n                \"innerError\": null,\n                \"debugInfo\": null,\n                \"additionalInfo\": null\n            },\n            \"correlation\": {\n                \"operation\": \"37605c3abcd69040a1158efcffc075b4\",\n                \"request\": \"41b6febef9ec16bc\"\n            },\n            \"environment\": \"uksouth\",\n            \"location\": \"uksouth\",\n            \"time\": \"2022-02-01T19:30:14.0639836+00:00\",\n            \"componentName\": \"Designer-MiddleTier-Service\"\n        }\n    }\n}"
     ]
    }
   ],
   "source": [
    "insights_job = submit_and_wait(ml_client, insights_pipeline_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bc8695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69e3860a",
   "metadata": {},
   "source": [
    "### Create Model and Data Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516b2fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from raiwidgets import ResponsibleAIDashboard\n",
    "from responsibleai import RAIInsights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8b0634",
   "metadata": {},
   "source": [
    "To use Responsible AI Dashboard, initialize a RAIInsights object upon which different components can be loaded.\n",
    "\n",
    "RAIInsights accepts the model, the full dataset, the test dataset, the target feature string, the task type string, and a list of strings of categorical feature names as its arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c941835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "dashboard_pipeline = Pipeline(steps=[('preprocess', feat_pipe), ('model', model)])\n",
    "rai_insights = RAIInsights(dashboard_pipeline, train_data, test_data, target_feature, 'classification',\n",
    "                             categorical_features=categorical_features, \n",
    "                             classes=[\"Less than median\", \"More than median\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1068ee",
   "metadata": {},
   "source": [
    "Add the components of the toolbox that are focused on model assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8587d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretability\n",
    "rai_insights.explainer.add()\n",
    "# Error Analysis\n",
    "rai_insights.error_analysis.add()\n",
    "# Counterfactuals: accepts total number of counterfactuals to generate, the label that they should have, and a list of \n",
    "                # strings of categorical feature names\n",
    "rai_insights.counterfactual.add(total_CFs=10, desired_class='opposite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec82a856",
   "metadata": {},
   "source": [
    "Once all the desired components have been loaded, compute insights on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127ec383",
   "metadata": {},
   "outputs": [],
   "source": [
    "rai_insights.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b5112c",
   "metadata": {},
   "source": [
    "Finally, visualize and explore the model insights. Use the resulting widget or follow the link to view this in a new tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73ad853",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResponsibleAIDashboard(rai_insights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6d610b",
   "metadata": {},
   "source": [
    "See this [developer blog](aka.ms/raidashboardblog) (Model Debugging Flow section) to learn more about this use case and how to use the dashboard to debug your housing price prediction model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
